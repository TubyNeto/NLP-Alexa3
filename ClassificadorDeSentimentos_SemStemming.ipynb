{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a052cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4311caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Alexa3Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01083ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37ce508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date  \n",
       "0    9 de outubro de 2019  \n",
       "1    8 de outubro de 2019  \n",
       "2    8 de outubro de 2019  \n",
       "3  13 de novembro de 2019  \n",
       "4   23 de outubro de 2019  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2321b8",
   "metadata": {},
   "source": [
    "## Distribuicao das Avaliacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b992d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per star rating:\n",
      "5    3475\n",
      "4     818\n",
      "3     304\n",
      "1     233\n",
      "2     150\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df['rating'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(df['rating']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d884c",
   "metadata": {},
   "source": [
    "## Tokenizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44ec2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd2b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8affefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "# É necessário instalar o pacote da lingua portuguesa no prompt do anaconda\n",
    "\n",
    "nlp = Portuguese()\n",
    "tokenizer = nlp.tokenizer\n",
    "text_token = []\n",
    "\n",
    "for line in df['text']: \n",
    "    tokens = tokenizer(line)\n",
    "    text_token.append(list(tokens))\n",
    "    \n",
    "df[\"text_token\"] = text_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8363911c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>[Sobre, o, produto, :, visual, muito, bonito, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[O, dispositivo, possui, 4, microfones, direci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[Comprei, o, Alexa, Echo, Dot, (, terceira, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>[Ainda, estou, me, adaptando, com, o, Echo, Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>[Acho, que, a, propaganda, desse, produto, est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \n",
       "0    9 de outubro de 2019  [Sobre, o, produto, :, visual, muito, bonito, ...  \n",
       "1    8 de outubro de 2019  [O, dispositivo, possui, 4, microfones, direci...  \n",
       "2    8 de outubro de 2019  [Comprei, o, Alexa, Echo, Dot, (, terceira, ge...  \n",
       "3  13 de novembro de 2019  [Ainda, estou, me, adaptando, com, o, Echo, Do...  \n",
       "4   23 de outubro de 2019  [Acho, que, a, propaganda, desse, produto, est...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9169adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_token.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4797734",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0be90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae9e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, nltk\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "\n",
    "stemmer = RSLPStemmer()\n",
    "\n",
    "stem_token_text = []\n",
    "\n",
    "for doc in text_token:\n",
    "    stem_list = []\n",
    "    for tkn in doc:\n",
    "        stem = stemmer.stem(str(tkn))\n",
    "        stem_list.append(stem)\n",
    "    stem_token_text.append(stem_list)\n",
    "df['Stem_teken_text'] = stem_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4659ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>[Sobre, o, produto, :, visual, muito, bonito, ...</td>\n",
       "      <td>[sobr, o, produt, :, visual, muit, bonit, e, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[O, dispositivo, possui, 4, microfones, direci...</td>\n",
       "      <td>[o, disposi, possu, 4, microfon, direc, do, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[Comprei, o, Alexa, Echo, Dot, (, terceira, ge...</td>\n",
       "      <td>[compr, o, alex, ech, dot, (, terc, ger, ), as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>[Ainda, estou, me, adaptando, com, o, Echo, Do...</td>\n",
       "      <td>[aind, est, me, adapt, com, o, ech, dot, ., fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>[Acho, que, a, propaganda, desse, produto, est...</td>\n",
       "      <td>[ach, que, a, propagand, dess, produt, est, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  [Sobre, o, produto, :, visual, muito, bonito, ...   \n",
       "1    8 de outubro de 2019  [O, dispositivo, possui, 4, microfones, direci...   \n",
       "2    8 de outubro de 2019  [Comprei, o, Alexa, Echo, Dot, (, terceira, ge...   \n",
       "3  13 de novembro de 2019  [Ainda, estou, me, adaptando, com, o, Echo, Do...   \n",
       "4   23 de outubro de 2019  [Acho, que, a, propaganda, desse, produto, est...   \n",
       "\n",
       "                                     Stem_teken_text  \n",
       "0  [sobr, o, produt, :, visual, muit, bonit, e, b...  \n",
       "1  [o, disposi, possu, 4, microfon, direc, do, to...  \n",
       "2  [compr, o, alex, ech, dot, (, terc, ger, ), as...  \n",
       "3  [aind, est, me, adapt, com, o, ech, dot, ., fi...  \n",
       "4  [ach, que, a, propagand, dess, produt, est, se...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9a25f",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b2d3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec5d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-6ac7513d89a9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Stem_teken_text\"][i] = \", \".join([str(item) for item in df[\"Stem_teken_text\"][i]])\n",
      "<ipython-input-16-6ac7513d89a9>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_token\"][i] = \", \".join([str(item) for item in df[\"text_token\"][i]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       Sobre, o, produto, :, visual, muito, bonito, e...\n",
       "1       O, dispositivo, possui, 4, microfones, direcio...\n",
       "2       Comprei, o, Alexa, Echo, Dot, (, terceira, ger...\n",
       "3       Ainda, estou, me, adaptando, com, o, Echo, Dot...\n",
       "4       Acho, que, a, propaganda, desse, produto, está...\n",
       "                              ...                        \n",
       "4975    Quería, muito, uma, caixa, de, som, para, ouvi...\n",
       "4976    Muito, bom, ,, melhor, ainda, do, que, eu, pen...\n",
       "4977    O, que, mais, gostei, ,, é, a, qualidade, de, ...\n",
       "4978    Muito, boa, ,, reconhece, muito, bem, a, voz, ...\n",
       "4979    Ótimo, produto, ,, desperta, ,, acende, a, lâm...\n",
       "Name: text_token, Length: 4980, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df[\"Stem_teken_text\"])):\n",
    "    df[\"Stem_teken_text\"][i] = \", \".join([str(item) for item in df[\"Stem_teken_text\"][i]])\n",
    "\n",
    "df[\"Stem_teken_text\"]\n",
    "\n",
    "for i in range(len(df[\"text_token\"])):\n",
    "    df[\"text_token\"][i] = \", \".join([str(item) for item in df[\"text_token\"][i]])\n",
    "\n",
    "df[\"text_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bbb5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1    8 de outubro de 2019  O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2    8 de outubro de 2019  Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3  13 de novembro de 2019  Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4   23 de outubro de 2019  Acho, que, a, propaganda, desse, produto, está...   \n",
       "\n",
       "                                     Stem_teken_text  \n",
       "0  sobr, o, produt, :, visual, muit, bonit, e, be...  \n",
       "1  o, disposi, possu, 4, microfon, direc, do, top...  \n",
       "2  compr, o, alex, ech, dot, (, terc, ger, ), ass...  \n",
       "3  aind, est, me, adapt, com, o, ech, dot, ., fiz...  \n",
       "4  ach, que, a, propagand, dess, produt, est, sen...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a709a",
   "metadata": {},
   "source": [
    "# Com Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2cdf7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4980x6422 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 217762 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsTexts = list(df[\"Stem_teken_text\"])\n",
    "countVectorizer = CountVectorizer(binary=True, ngram_range = (1,1))\n",
    "bowTransformer = countVectorizer.fit(reviewsTexts)\n",
    "reviewsTexts = bowTransformer.transform(reviewsTexts)\n",
    "\n",
    "reviewsTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb161e",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae8c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviewsTexts, df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0061d6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce004ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 2.7583878 ,  5.50368466,  8.36089926, 11.01343479, 14.1753222 ,\n",
       "        17.13299446, 19.45793748,  2.70292721,  5.13091969,  7.65200558,\n",
       "        10.2715169 , 12.70605831, 15.47799611, 15.09976087]),\n",
       " 'std_fit_time': array([0.06435578, 0.02870664, 0.0615265 , 0.16494015, 0.3290149 ,\n",
       "        0.14550623, 0.24682694, 0.06242111, 0.08731035, 0.02755655,\n",
       "        0.12313464, 0.15483543, 0.359268  , 1.72658247]),\n",
       " 'mean_score_time': array([0.04210539, 0.075669  , 0.11251478, 0.15382428, 0.21958265,\n",
       "        0.24092703, 0.27301984, 0.03873382, 0.06442761, 0.10001502,\n",
       "        0.13045397, 0.16476889, 0.19296875, 0.1452136 ]),\n",
       " 'std_score_time': array([0.00457749, 0.00295886, 0.00356941, 0.00868533, 0.02679685,\n",
       "        0.01805126, 0.01522187, 0.00319872, 0.00061737, 0.00391865,\n",
       "        0.00328912, 0.00665904, 0.0146287 , 0.02099148]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 250, 300, 350, 50, 100, 150, 200,\n",
       "                    250, 300, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'n_estimators': 50},\n",
       "  {'criterion': 'gini', 'n_estimators': 100},\n",
       "  {'criterion': 'gini', 'n_estimators': 150},\n",
       "  {'criterion': 'gini', 'n_estimators': 200},\n",
       "  {'criterion': 'gini', 'n_estimators': 250},\n",
       "  {'criterion': 'gini', 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'n_estimators': 350},\n",
       "  {'criterion': 'entropy', 'n_estimators': 50},\n",
       "  {'criterion': 'entropy', 'n_estimators': 100},\n",
       "  {'criterion': 'entropy', 'n_estimators': 150},\n",
       "  {'criterion': 'entropy', 'n_estimators': 200},\n",
       "  {'criterion': 'entropy', 'n_estimators': 250},\n",
       "  {'criterion': 'entropy', 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'n_estimators': 350}],\n",
       " 'split0_test_f1_micro': array([0.69770774, 0.69770774, 0.6991404 , 0.70057307, 0.70200573,\n",
       "        0.70057307, 0.6991404 , 0.69627507, 0.69770774, 0.69770774,\n",
       "        0.69627507, 0.69770774, 0.69770774, 0.69770774]),\n",
       " 'split1_test_f1_micro': array([0.70301291, 0.70157819, 0.70157819, 0.69870875, 0.70014347,\n",
       "        0.69870875, 0.69727403, 0.69870875, 0.69583931, 0.69727403,\n",
       "        0.69870875, 0.69727403, 0.69870875, 0.69727403]),\n",
       " 'split2_test_f1_micro': array([0.70301291, 0.69727403, 0.69870875, 0.69583931, 0.69870875,\n",
       "        0.70014347, 0.69727403, 0.69727403, 0.69870875, 0.69727403,\n",
       "        0.69727403, 0.69870875, 0.69727403, 0.69727403]),\n",
       " 'split3_test_f1_micro': array([0.70014347, 0.70157819, 0.69870875, 0.70301291, 0.69583931,\n",
       "        0.70014347, 0.69870875, 0.70014347, 0.69727403, 0.70014347,\n",
       "        0.69727403, 0.69727403, 0.69727403, 0.69727403]),\n",
       " 'split4_test_f1_micro': array([0.69870875, 0.69727403, 0.69870875, 0.69583931, 0.69727403,\n",
       "        0.69583931, 0.69583931, 0.69583931, 0.69583931, 0.69583931,\n",
       "        0.69583931, 0.69583931, 0.69583931, 0.69583931]),\n",
       " 'mean_test_f1_micro': array([0.70051716, 0.69908244, 0.69936897, 0.69879467, 0.69879426,\n",
       "        0.69908161, 0.69764731, 0.69764813, 0.69707383, 0.69764772,\n",
       "        0.69707424, 0.69736077, 0.69736077, 0.69707383]),\n",
       " 'std_test_f1_micro': array([0.00217993, 0.00204392, 0.00111719, 0.00277243, 0.00215333,\n",
       "        0.0017396 , 0.00117503, 0.00159052, 0.00111022, 0.00139871,\n",
       "        0.00099148, 0.00092383, 0.00092383, 0.00063971]),\n",
       " 'rank_test_f1_micro': array([ 1,  3,  2,  5,  6,  4,  9,  7, 13,  8, 12, 10, 10, 13])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np \n",
    "\n",
    "scores = ['f1_micro']\n",
    "\n",
    "parameters = {\n",
    "     'n_estimators': list(range(50, 351, 50)),\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( RandomForestClassifier(), \n",
    "                            parameters,\n",
    "                            n_jobs = -1,    \n",
    "                            scoring = scores,\n",
    "                            cv = 5,\n",
    "                            refit = 'f1_micro', \n",
    "                            verbose=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438ca8e",
   "metadata": {},
   "source": [
    "## Melhores Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ac600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 50}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fe04f",
   "metadata": {},
   "source": [
    "## Testando o Modelo com os Parametros Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7b7391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randomForest = RandomForestClassifier(criterion= grid_search.best_params_['criterion'], n_estimators = grid_search.best_params_['n_estimators']).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da32fff",
   "metadata": {},
   "source": [
    "## Metricas Obtidas sobre a Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6089fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        71\n",
      "           2       0.00      0.00      0.00        50\n",
      "           3       0.00      0.00      0.00        95\n",
      "           4       0.33      0.03      0.06       231\n",
      "           5       0.71      1.00      0.83      1047\n",
      "\n",
      "    accuracy                           0.70      1494\n",
      "   macro avg       0.21      0.21      0.18      1494\n",
      "weighted avg       0.55      0.70      0.59      1494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35d23266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7021419009370816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, randomForest.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c7e5c",
   "metadata": {},
   "source": [
    "# Sem Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b944ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4980x12202 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 227068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsTexts = list(df[\"text_token\"])\n",
    "countVectorizer = CountVectorizer(binary=True, ngram_range = (1,1))\n",
    "bowTransformer = countVectorizer.fit(reviewsTexts)\n",
    "reviewsTexts = bowTransformer.transform(reviewsTexts)\n",
    "\n",
    "reviewsTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a497ce",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff36ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviewsTexts, df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f2c80",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38ecce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.93248191,  3.80822859,  5.81202536,  7.81817775, 10.0091331 ,\n",
       "        12.4716475 , 14.61805677,  1.88293343,  3.80436711,  5.68830872,\n",
       "         7.60744662,  9.52415338, 11.48396182, 11.1919208 ]),\n",
       " 'std_fit_time': array([0.05055936, 0.04397097, 0.08458209, 0.12885349, 0.21962294,\n",
       "        0.20341583, 0.28877008, 0.0398531 , 0.07962711, 0.0353168 ,\n",
       "        0.04620972, 0.09763094, 0.19374405, 1.0404727 ]),\n",
       " 'mean_score_time': array([0.02496028, 0.04715571, 0.06992812, 0.10647402, 0.11599097,\n",
       "        0.14402041, 0.17574334, 0.02194147, 0.04298654, 0.06675076,\n",
       "        0.08487711, 0.10565028, 0.12379742, 0.09567251]),\n",
       " 'std_score_time': array([0.00175468, 0.00227922, 0.00262073, 0.01404308, 0.00502101,\n",
       "        0.00414142, 0.00640516, 0.00063068, 0.00179396, 0.00355001,\n",
       "        0.00297933, 0.00295275, 0.01146969, 0.00863326]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 250, 300, 350, 50, 100, 150, 200,\n",
       "                    250, 300, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'n_estimators': 50},\n",
       "  {'criterion': 'gini', 'n_estimators': 100},\n",
       "  {'criterion': 'gini', 'n_estimators': 150},\n",
       "  {'criterion': 'gini', 'n_estimators': 200},\n",
       "  {'criterion': 'gini', 'n_estimators': 250},\n",
       "  {'criterion': 'gini', 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'n_estimators': 350},\n",
       "  {'criterion': 'entropy', 'n_estimators': 50},\n",
       "  {'criterion': 'entropy', 'n_estimators': 100},\n",
       "  {'criterion': 'entropy', 'n_estimators': 150},\n",
       "  {'criterion': 'entropy', 'n_estimators': 200},\n",
       "  {'criterion': 'entropy', 'n_estimators': 250},\n",
       "  {'criterion': 'entropy', 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'n_estimators': 350}],\n",
       " 'split0_test_f1_micro': array([0.70630372, 0.70630372, 0.70916905, 0.70630372, 0.70773639,\n",
       "        0.70916905, 0.70773639, 0.70487106, 0.70630372, 0.70630372,\n",
       "        0.70630372, 0.70630372, 0.70630372, 0.70630372]),\n",
       " 'split1_test_f1_micro': array([0.71162123, 0.70875179, 0.70731707, 0.70875179, 0.70875179,\n",
       "        0.71018651, 0.70731707, 0.70731707, 0.70875179, 0.70875179,\n",
       "        0.70875179, 0.70875179, 0.70875179, 0.70875179]),\n",
       " 'split2_test_f1_micro': array([0.70875179, 0.70588235, 0.70731707, 0.70731707, 0.70875179,\n",
       "        0.70875179, 0.70731707, 0.71018651, 0.70731707, 0.70875179,\n",
       "        0.70731707, 0.70731707, 0.70731707, 0.70731707]),\n",
       " 'split3_test_f1_micro': array([0.70588235, 0.70731707, 0.70731707, 0.70588235, 0.70731707,\n",
       "        0.70588235, 0.70731707, 0.70731707, 0.70731707, 0.70731707,\n",
       "        0.70731707, 0.70731707, 0.70731707, 0.70731707]),\n",
       " 'split4_test_f1_micro': array([0.70588235, 0.70731707, 0.70731707, 0.70731707, 0.70875179,\n",
       "        0.70731707, 0.70731707, 0.71018651, 0.70731707, 0.70731707,\n",
       "        0.70731707, 0.70731707, 0.70731707, 0.70731707]),\n",
       " 'mean_test_f1_micro': array([0.70768829, 0.7071144 , 0.70768747, 0.7071144 , 0.70826177,\n",
       "        0.70826136, 0.70740094, 0.70797565, 0.70740135, 0.70768829,\n",
       "        0.70740135, 0.70740135, 0.70740135, 0.70740135]),\n",
       " 'std_test_f1_micro': array([0.00223781, 0.00099382, 0.00074079, 0.00099382, 0.00061463,\n",
       "        0.00150479, 0.00016773, 0.00201404, 0.000781  , 0.0009439 ,\n",
       "        0.000781  , 0.000781  , 0.000781  , 0.000781  ]),\n",
       " 'rank_test_f1_micro': array([ 4, 13,  6, 13,  1,  2, 12,  3,  7,  5,  7,  7,  7,  7])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np \n",
    "\n",
    "scores = ['f1_micro']\n",
    "\n",
    "parameters = {\n",
    "     'n_estimators': list(range(50, 351, 50)),\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( RandomForestClassifier(), \n",
    "                            parameters,\n",
    "                            n_jobs = -1,    \n",
    "                            scoring = scores,\n",
    "                            cv = 5,\n",
    "                            refit = 'f1_micro', \n",
    "                            verbose=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d56d01",
   "metadata": {},
   "source": [
    "## Melhores Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbbe3e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 250}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1c151",
   "metadata": {},
   "source": [
    "## Testando o Modelo com os Parametros Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "815661cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randomForest = RandomForestClassifier(criterion= grid_search.best_params_['criterion'], n_estimators = grid_search.best_params_['n_estimators']).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f60ce6",
   "metadata": {},
   "source": [
    "## Metricas Obtidas sobre a Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ebaf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        63\n",
      "           2       0.00      0.00      0.00        51\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.50      0.00      0.01       270\n",
      "           5       0.68      1.00      0.81      1010\n",
      "\n",
      "    accuracy                           0.68      1494\n",
      "   macro avg       0.24      0.20      0.16      1494\n",
      "weighted avg       0.55      0.68      0.55      1494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b64577b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6767068273092369"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, randomForest.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11d812",
   "metadata": {},
   "source": [
    "Apos a execução sem e com stemming, obteve-se um f1-score ligeiramente melhor com o stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1cf2c8",
   "metadata": {},
   "source": [
    "# Aplicacao da CNN - Sem Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23006a",
   "metadata": {},
   "source": [
    " ## Consultando o Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dfc4a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sobre, o, produto, :, visual, muito, bonito, e...\n",
       "1       O, dispositivo, possui, 4, microfones, direcio...\n",
       "2       Comprei, o, Alexa, Echo, Dot, (, terceira, ger...\n",
       "3       Ainda, estou, me, adaptando, com, o, Echo, Dot...\n",
       "4       Acho, que, a, propaganda, desse, produto, está...\n",
       "                              ...                        \n",
       "4975    Quería, muito, uma, caixa, de, som, para, ouvi...\n",
       "4976    Muito, bom, ,, melhor, ainda, do, que, eu, pen...\n",
       "4977    O, que, mais, gostei, ,, é, a, qualidade, de, ...\n",
       "4978    Muito, boa, ,, reconhece, muito, bem, a, voz, ...\n",
       "4979    Ótimo, produto, ,, desperta, ,, acende, a, lâm...\n",
       "Name: text_token, Length: 4980, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abd15434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho do vocabulário é:  4980\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "word_count = Counter()\n",
    "for token in list(df['text_token']): \n",
    "    word_count[token] += 1\n",
    "\n",
    "word_count\n",
    "vocabSize = len(word_count)\n",
    "\n",
    "print(\"O tamanho do vocabulário é: \", vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2acc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.0-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=4cffc6d2bbda1dea7466d4ceb9ce1643e059ccab7872c665dd170044936fb445\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9c0b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "vocab_size = vocabSize\n",
    "oov_token = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(df['text_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe6cd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_to_sequence\"] = tokenizer.texts_to_sequences(df['text_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d21326",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd901157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 100\n",
    "padding_type = \"post\"\n",
    "trunction_type=\"post\"\n",
    "text_to_sequence_padded = pad_sequences(df[\"text_to_sequence\"], maxlen=max_length, padding=padding_type,\n",
    "                       truncating=trunction_type)\n",
    "df[\"text_to_sequence_padded\"] = list(text_to_sequence_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3cb2ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "      <th>text_to_sequence</th>\n",
       "      <th>text_to_sequence_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "      <td>[162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...</td>\n",
       "      <td>[162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "      <td>[5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...</td>\n",
       "      <td>[5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "      <td>[59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...</td>\n",
       "      <td>[59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "      <td>[40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...</td>\n",
       "      <td>[40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "      <td>[155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...</td>\n",
       "      <td>[155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1    8 de outubro de 2019  O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2    8 de outubro de 2019  Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3  13 de novembro de 2019  Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4   23 de outubro de 2019  Acho, que, a, propaganda, desse, produto, está...   \n",
       "\n",
       "                                     Stem_teken_text  \\\n",
       "0  sobr, o, produt, :, visual, muit, bonit, e, be...   \n",
       "1  o, disposi, possu, 4, microfon, direc, do, top...   \n",
       "2  compr, o, alex, ech, dot, (, terc, ger, ), ass...   \n",
       "3  aind, est, me, adapt, com, o, ech, dot, ., fiz...   \n",
       "4  ach, que, a, propagand, dess, produt, est, sen...   \n",
       "\n",
       "                                    text_to_sequence  \\\n",
       "0  [162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...   \n",
       "1  [5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...   \n",
       "2  [59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...   \n",
       "3  [40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...   \n",
       "4  [155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...   \n",
       "\n",
       "                             text_to_sequence_padded  \n",
       "0  [162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...  \n",
       "1  [5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...  \n",
       "2  [59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...  \n",
       "3  [40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...  \n",
       "4  [155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f511e63",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c4ac770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 929594 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)  \n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove_s100.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    \n",
    "    coefs = []\n",
    "    for coef in values[1:]:\n",
    "        if (is_float(coef)):\n",
    "            coefs.append(coef)\n",
    "    \n",
    "    coefs = np.asarray(coefs, dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "72ca61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "\n",
    "for i, line in enumerate(list(word_count.keys())):\n",
    "    for word in list(word_count.keys())[i].split(\", \"):\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if (embedding_vector is not None):\n",
    "            embedding_dict[word] = embedding_vector\n",
    "        else:\n",
    "            embedding_dict[word] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1bd1e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_count) + 1, 100))\n",
    "\n",
    "for i, word in enumerate(list(word_count.keys())):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f61fbbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c65e8",
   "metadata": {},
   "source": [
    "## Criando a Camada de Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7d87886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(input_dim=len(word_count) + 1,\n",
    "                            output_dim=100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=100,\n",
    "                            trainable=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fef804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea11d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f58761b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Embedded = []\n",
    "\n",
    "for i in range(len(df[\"text_token\"])):\n",
    "    line = list(df[\"text_token\"])[i].split(\", \")\n",
    "    embeddedLine = []\n",
    "    for i, token in enumerate(line[:20]): \n",
    "        embeddedLine.append(embedding_dict[token])\n",
    "    Embedded.append(np.asarray(embeddedLine, dtype=object))    \n",
    "    \n",
    "df[\"Embedded\"] = Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1432cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRatings = []\n",
    "\n",
    "for rating in df[\"rating\"]:\n",
    "    if rating==1 or rating==2 or rating==3:\n",
    "        newRatings.append(0)\n",
    "    else:\n",
    "        newRatings.append(1)\n",
    "        \n",
    "df[\"rating\"] = newRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e8c7d371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "      <th>text_to_sequence</th>\n",
       "      <th>text_to_sequence_padded</th>\n",
       "      <th>Stem_Embedded</th>\n",
       "      <th>Embedded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>1</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "      <td>[162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...</td>\n",
       "      <td>[162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "      <td>[5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...</td>\n",
       "      <td>[5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "      <td>[59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...</td>\n",
       "      <td>[59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "      <td>[40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...</td>\n",
       "      <td>[40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>0</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "      <td>[155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...</td>\n",
       "      <td>[155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>MELHOR COMPRA DA MINHA VIDA</td>\n",
       "      <td>Quería muito uma caixa de som para ouvir minha...</td>\n",
       "      <td>1</td>\n",
       "      <td>25 de novembro de 2020</td>\n",
       "      <td>Quería, muito, uma, caixa, de, som, para, ouvi...</td>\n",
       "      <td>querí, muit, uma, caix, de, som, par, ouv, min...</td>\n",
       "      <td>[1, 11, 15, 91, 3, 19, 9, 75, 142, 405, 851, 7...</td>\n",
       "      <td>[1, 11, 15, 91, 3, 19, 9, 75, 142, 405, 851, 7...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>SUPIMPA!!!!</td>\n",
       "      <td>Muito bom, melhor ainda do que eu pense, apena...</td>\n",
       "      <td>1</td>\n",
       "      <td>1 de dezembro de 2020</td>\n",
       "      <td>Muito, bom, ,, melhor, ainda, do, que, eu, pen...</td>\n",
       "      <td>muit, bom, ,, melhor, aind, do, que, eu, pens,...</td>\n",
       "      <td>[11, 43, 66, 40, 14, 6, 31, 1614, 120, 963, 39...</td>\n",
       "      <td>[11, 43, 66, 40, 14, 6, 31, 1614, 120, 963, 39...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>A melhor</td>\n",
       "      <td>O que mais gostei, é a qualidade de áudio, vol...</td>\n",
       "      <td>1</td>\n",
       "      <td>17 de junho de 2021</td>\n",
       "      <td>O, que, mais, gostei, ,, é, a, qualidade, de, ...</td>\n",
       "      <td>o, que, mais, gost, ,, é, a, qual, de, áudi, ,...</td>\n",
       "      <td>[5, 6, 21, 87, 7, 2, 33, 3, 198, 94, 67, 8, 19...</td>\n",
       "      <td>[5, 6, 21, 87, 7, 2, 33, 3, 198, 94, 67, 8, 19...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>A Alexa compensa muito comprar.</td>\n",
       "      <td>Muito boa, reconhece muito bem a voz , o volum...</td>\n",
       "      <td>1</td>\n",
       "      <td>12 de agosto de 2020</td>\n",
       "      <td>Muito, boa, ,, reconhece, muito, bem, a, voz, ...</td>\n",
       "      <td>muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...</td>\n",
       "      <td>[11, 64, 135, 11, 26, 2, 30, 5, 94, 7, 11, 43,...</td>\n",
       "      <td>[11, 64, 135, 11, 26, 2, 30, 5, 94, 7, 11, 43,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Muito satisfeito</td>\n",
       "      <td>Ótimo produto, desperta, acende a lâmpada, toc...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de janeiro de 2021</td>\n",
       "      <td>Ótimo, produto, ,, desperta, ,, acende, a, lâm...</td>\n",
       "      <td>ótim, produt, ,, despert, ,, acend, a, lâmp, ,...</td>\n",
       "      <td>[84, 27, 3866, 1106, 2, 387, 286, 53, 93, 7, 7...</td>\n",
       "      <td>[84, 27, 3866, 1106, 2, 387, 286, 53, 93, 7, 7...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4980 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                      Excelente custo benefício   \n",
       "1     Péssimo início - defeito ao tirar da caixa   \n",
       "2                             Excelente produto!   \n",
       "3                               Muito Satisfeito   \n",
       "4                   Decepção é o meu sentimento.   \n",
       "...                                          ...   \n",
       "4975                 MELHOR COMPRA DA MINHA VIDA   \n",
       "4976                                 SUPIMPA!!!!   \n",
       "4977                                    A melhor   \n",
       "4978             A Alexa compensa muito comprar.   \n",
       "4979                            Muito satisfeito   \n",
       "\n",
       "                                                   text  rating  \\\n",
       "0     Sobre o produto: visual muito bonito e bem aca...       1   \n",
       "1     O dispositivo possui 4 microfones direcionais ...       0   \n",
       "2     Comprei o Alexa Echo Dot (terceira geração) as...       1   \n",
       "3     Ainda estou me adaptando com o Echo Dot.Fiz a ...       1   \n",
       "4     Acho que a propaganda desse produto está sendo...       0   \n",
       "...                                                 ...     ...   \n",
       "4975  Quería muito uma caixa de som para ouvir minha...       1   \n",
       "4976  Muito bom, melhor ainda do que eu pense, apena...       1   \n",
       "4977  O que mais gostei, é a qualidade de áudio, vol...       1   \n",
       "4978  Muito boa, reconhece muito bem a voz , o volum...       1   \n",
       "4979  Ótimo produto, desperta, acende a lâmpada, toc...       1   \n",
       "\n",
       "                        date  \\\n",
       "0       9 de outubro de 2019   \n",
       "1       8 de outubro de 2019   \n",
       "2       8 de outubro de 2019   \n",
       "3     13 de novembro de 2019   \n",
       "4      23 de outubro de 2019   \n",
       "...                      ...   \n",
       "4975  25 de novembro de 2020   \n",
       "4976   1 de dezembro de 2020   \n",
       "4977     17 de junho de 2021   \n",
       "4978    12 de agosto de 2020   \n",
       "4979    8 de janeiro de 2021   \n",
       "\n",
       "                                             text_token  \\\n",
       "0     Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1     O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2     Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3     Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4     Acho, que, a, propaganda, desse, produto, está...   \n",
       "...                                                 ...   \n",
       "4975  Quería, muito, uma, caixa, de, som, para, ouvi...   \n",
       "4976  Muito, bom, ,, melhor, ainda, do, que, eu, pen...   \n",
       "4977  O, que, mais, gostei, ,, é, a, qualidade, de, ...   \n",
       "4978  Muito, boa, ,, reconhece, muito, bem, a, voz, ...   \n",
       "4979  Ótimo, produto, ,, desperta, ,, acende, a, lâm...   \n",
       "\n",
       "                                        Stem_teken_text  \\\n",
       "0     sobr, o, produt, :, visual, muit, bonit, e, be...   \n",
       "1     o, disposi, possu, 4, microfon, direc, do, top...   \n",
       "2     compr, o, alex, ech, dot, (, terc, ger, ), ass...   \n",
       "3     aind, est, me, adapt, com, o, ech, dot, ., fiz...   \n",
       "4     ach, que, a, propagand, dess, produt, est, sen...   \n",
       "...                                                 ...   \n",
       "4975  querí, muit, uma, caix, de, som, par, ouv, min...   \n",
       "4976  muit, bom, ,, melhor, aind, do, que, eu, pens,...   \n",
       "4977  o, que, mais, gost, ,, é, a, qual, de, áudi, ,...   \n",
       "4978  muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...   \n",
       "4979  ótim, produt, ,, despert, ,, acend, a, lâmp, ,...   \n",
       "\n",
       "                                       text_to_sequence  \\\n",
       "0     [162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...   \n",
       "1     [5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...   \n",
       "2     [59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...   \n",
       "3     [40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...   \n",
       "4     [155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...   \n",
       "...                                                 ...   \n",
       "4975  [1, 11, 15, 91, 3, 19, 9, 75, 142, 405, 851, 7...   \n",
       "4976  [11, 43, 66, 40, 14, 6, 31, 1614, 120, 963, 39...   \n",
       "4977  [5, 6, 21, 87, 7, 2, 33, 3, 198, 94, 67, 8, 19...   \n",
       "4978  [11, 64, 135, 11, 26, 2, 30, 5, 94, 7, 11, 43,...   \n",
       "4979  [84, 27, 3866, 1106, 2, 387, 286, 53, 93, 7, 7...   \n",
       "\n",
       "                                text_to_sequence_padded  \\\n",
       "0     [162, 5, 27, 1328, 11, 487, 4, 26, 1592, 1714,...   \n",
       "1     [5, 104, 265, 227, 327, 4894, 14, 580, 617, 21...   \n",
       "2     [59, 5, 17, 29, 41, 1198, 161, 176, 6, 272, 12...   \n",
       "3     [40, 48, 38, 1380, 10, 5, 29, 41, 311, 2, 358,...   \n",
       "4     [155, 6, 2, 1288, 631, 27, 63, 200, 1017, 3, 2...   \n",
       "...                                                 ...   \n",
       "4975  [1, 11, 15, 91, 3, 19, 9, 75, 142, 405, 851, 7...   \n",
       "4976  [11, 43, 66, 40, 14, 6, 31, 1614, 120, 963, 39...   \n",
       "4977  [5, 6, 21, 87, 7, 2, 33, 3, 198, 94, 67, 8, 19...   \n",
       "4978  [11, 64, 135, 11, 26, 2, 30, 5, 94, 7, 11, 43,...   \n",
       "4979  [84, 27, 3866, 1106, 2, 387, 286, 53, 93, 7, 7...   \n",
       "\n",
       "                                          Stem_Embedded  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                 ...   \n",
       "4975  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4976  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4977  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4978  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4979  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                               Embedded  \n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "...                                                 ...  \n",
       "4975  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4976  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4977  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4978  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4979  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[4980 rows x 10 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00e86f",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed6649d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_to_sequence_padded'], df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "92724bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4235    [11, 21, 108, 14, 6, 156, 745, 727, 21, 848, 2...\n",
       "1072    [107, 8, 25, 8, 391, 5, 6, 63, 2425, 660, 791,...\n",
       "1565    [9, 309, 3, 37, 108, 7, 21, 3093, 4, 612, 6, 5...\n",
       "4386    [373, 5, 27, 326, 923, 32, 31, 936, 4, 79, 11,...\n",
       "912     [326, 13, 27, 6, 630, 2, 11, 69, 20, 136, 10, ...\n",
       "                              ...                        \n",
       "1820    [1513, 6, 39, 327, 38, 1, 2, 15, 532, 284, 20,...\n",
       "4707    [462, 142, 223, 505, 9, 167, 2, 387, 14, 188, ...\n",
       "2596    [95, 5, 29, 41, 7, 11, 2994, 93, 135, 11, 14, ...\n",
       "1726    [8, 80, 781, 22, 110, 7, 2278, 177, 213, 25, 1...\n",
       "4437    [2562, 3, 728, 20, 22, 429, 850, 6, 1639, 12, ...\n",
       "Name: text_to_sequence_padded, Length: 3486, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bbbeac2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4476    [11, 109, 3, 15, 181, 3, 19, 807, 833, 2, 1122...\n",
       "3236    [314, 12, 457, 56, 3, 506, 8, 130, 123, 21, 92...\n",
       "3118    [57, 105, 59, 247, 9, 75, 53, 5, 19, 7, 84, 9,...\n",
       "4628    [2, 17, 111, 237, 18, 354, 57, 35, 1870, 53, 1...\n",
       "4958    [2, 315, 8, 318, 47, 320, 131, 65, 1, 2, 13, 6...\n",
       "                              ...                        \n",
       "3228    [31, 394, 236, 1652, 2634, 520, 142, 223, 96, ...\n",
       "386     [7, 13, 84, 27, 5, 19, 25, 15, 57, 33, 96, 130...\n",
       "396     [87, 98, 553, 3, 153, 168, 35, 152, 15, 53, 27...\n",
       "1411    [12, 7, 314, 9, 493, 762, 24, 5, 212, 458, 11,...\n",
       "1199    [27, 240, 9, 238, 201, 1110, 211, 766, 1307, 1...\n",
       "Name: text_to_sequence_padded, Length: 1494, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "186dc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = np.zeros((len(X_train), 100))\n",
    "\n",
    "for i in range (len(X_train)):\n",
    "    X_train_tensor[i] = X_train.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bf23235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486, 100)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cf28fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = np.zeros((len(X_test), 100))\n",
    "\n",
    "for i in range (len(X_test)):\n",
    "    X_test_tensor[i] = X_test.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b8c89143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 100)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "78fcd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.stack(y_train, axis=0)  \n",
    "y_test = np.stack(y_test, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4286e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c554e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "20f16b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "109/109 [==============================] - 2s 11ms/step - loss: 0.6746 - accuracy: 0.8603 - val_loss: 0.6558 - val_accuracy: 0.8661\n",
      "Epoch 2/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.6399 - accuracy: 0.8603 - val_loss: 0.6225 - val_accuracy: 0.8661\n",
      "Epoch 3/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.6091 - accuracy: 0.8603 - val_loss: 0.5931 - val_accuracy: 0.8661\n",
      "Epoch 4/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.5818 - accuracy: 0.8603 - val_loss: 0.5668 - val_accuracy: 0.8661\n",
      "Epoch 5/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.5577 - accuracy: 0.8603 - val_loss: 0.5437 - val_accuracy: 0.8661\n",
      "Epoch 6/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.5366 - accuracy: 0.8603 - val_loss: 0.5233 - val_accuracy: 0.8661\n",
      "Epoch 7/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.5182 - accuracy: 0.8603 - val_loss: 0.5056 - val_accuracy: 0.8661\n",
      "Epoch 8/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.5020 - accuracy: 0.8603 - val_loss: 0.4904 - val_accuracy: 0.8661\n",
      "Epoch 9/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4879 - accuracy: 0.8603 - val_loss: 0.4767 - val_accuracy: 0.8661\n",
      "Epoch 10/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4755 - accuracy: 0.8603 - val_loss: 0.4647 - val_accuracy: 0.8661\n",
      "Epoch 11/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4649 - accuracy: 0.8603 - val_loss: 0.4544 - val_accuracy: 0.8661\n",
      "Epoch 12/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4556 - accuracy: 0.8603 - val_loss: 0.4456 - val_accuracy: 0.8661\n",
      "Epoch 13/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4477 - accuracy: 0.8603 - val_loss: 0.4378 - val_accuracy: 0.8661\n",
      "Epoch 14/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4408 - accuracy: 0.8603 - val_loss: 0.4311 - val_accuracy: 0.8661\n",
      "Epoch 15/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4349 - accuracy: 0.8603 - val_loss: 0.4254 - val_accuracy: 0.8661\n",
      "Epoch 16/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4298 - accuracy: 0.8603 - val_loss: 0.4204 - val_accuracy: 0.8661\n",
      "Epoch 17/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4256 - accuracy: 0.8603 - val_loss: 0.4161 - val_accuracy: 0.8661\n",
      "Epoch 18/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4219 - accuracy: 0.8603 - val_loss: 0.4125 - val_accuracy: 0.8661\n",
      "Epoch 19/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4188 - accuracy: 0.8603 - val_loss: 0.4094 - val_accuracy: 0.8661\n",
      "Epoch 20/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4163 - accuracy: 0.8603 - val_loss: 0.4068 - val_accuracy: 0.8661\n",
      "Epoch 21/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4141 - accuracy: 0.8603 - val_loss: 0.4046 - val_accuracy: 0.8661\n",
      "Epoch 22/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4122 - accuracy: 0.8603 - val_loss: 0.4027 - val_accuracy: 0.8661\n",
      "Epoch 23/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4107 - accuracy: 0.8603 - val_loss: 0.4011 - val_accuracy: 0.8661\n",
      "Epoch 24/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4095 - accuracy: 0.8603 - val_loss: 0.3999 - val_accuracy: 0.8661\n",
      "Epoch 25/30\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.4084 - accuracy: 0.8603 - val_loss: 0.3988 - val_accuracy: 0.8661\n",
      "Epoch 26/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4076 - accuracy: 0.8603 - val_loss: 0.3979 - val_accuracy: 0.8661\n",
      "Epoch 27/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4069 - accuracy: 0.8603 - val_loss: 0.3971 - val_accuracy: 0.8661\n",
      "Epoch 28/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4064 - accuracy: 0.8603 - val_loss: 0.3965 - val_accuracy: 0.8661\n",
      "Epoch 29/30\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.4059 - accuracy: 0.8603 - val_loss: 0.3960 - val_accuracy: 0.8661\n",
      "Epoch 30/30\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.4056 - accuracy: 0.8603 - val_loss: 0.3956 - val_accuracy: 0.8661\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tensor, y_train, epochs=30, validation_data=(X_test_tensor, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "da6b3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8661\n",
      "Testing Accuracy is 86.61311864852905 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_tensor,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81f02",
   "metadata": {},
   "source": [
    "A acurácia apresentou uma pequena melhora quando compara com o modelo com Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937ea18",
   "metadata": {},
   "source": [
    "## Tunning de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "de9f5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_optimize(num_filters, kernel_size):\n",
    "    model = Sequential([\n",
    "      embedding_layer,\n",
    "      Conv1D(num_filters, kernel_size, activation='relu'),\n",
    "      GlobalMaxPooling1D(),\n",
    "      Dense(10, activation='relu'),\n",
    "      Dense(1, activation='sigmoid')])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e64a10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"num_filters\":[32, 64, 128, 256],\n",
    "    \"kernel_size\":[3, 5, 7, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a3cc22ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-a77f2410e9dd>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model_to_optimize,\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=model_to_optimize,\n",
    "                        epochs=20,\n",
    "                        batch_size=10,\n",
    "                        verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7d32a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gridSearch = GridSearchCV(estimator=model, param_grid=params,\n",
    "                              cv=5, verbose=1)\n",
    "search_result = gridSearch.fit(X_train_tensor, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a85401f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = gridSearch.score(X_test_tensor, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e58f9840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8661311864852905"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "952fda67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_size': 3, 'num_filters': 32}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c430ffd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel_size</th>\n",
       "      <th>param_num_filters</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.731801</td>\n",
       "      <td>0.447703</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 32}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.877734</td>\n",
       "      <td>0.505969</td>\n",
       "      <td>0.175307</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 64}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.478212</td>\n",
       "      <td>0.371559</td>\n",
       "      <td>0.186681</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 128}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.559495</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.215593</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 256}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.049811</td>\n",
       "      <td>0.082001</td>\n",
       "      <td>0.187081</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 32}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.118650</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>0.191478</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 64}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.515175</td>\n",
       "      <td>2.688280</td>\n",
       "      <td>0.228733</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 128}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.925288</td>\n",
       "      <td>0.803520</td>\n",
       "      <td>0.275194</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 256}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.539478</td>\n",
       "      <td>0.770111</td>\n",
       "      <td>0.187956</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 32}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.737521</td>\n",
       "      <td>4.823608</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 64}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.733952</td>\n",
       "      <td>2.882164</td>\n",
       "      <td>0.382448</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 128}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.999094</td>\n",
       "      <td>5.021282</td>\n",
       "      <td>0.452244</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>7</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 256}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38.479821</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.316802</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 32}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.780118</td>\n",
       "      <td>0.420964</td>\n",
       "      <td>0.353218</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 64}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>57.920039</td>\n",
       "      <td>4.530763</td>\n",
       "      <td>0.416654</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 128}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81.767273</td>\n",
       "      <td>3.730433</td>\n",
       "      <td>0.514749</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 256}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.731801      0.447703         0.172408        0.010776   \n",
       "1       11.877734      0.505969         0.175307        0.008869   \n",
       "2       14.478212      0.371559         0.186681        0.007479   \n",
       "3       21.559495      0.382594         0.215593        0.018344   \n",
       "4       16.049811      0.082001         0.187081        0.007390   \n",
       "5       18.118650      0.155644         0.191478        0.006501   \n",
       "6       25.515175      2.688280         0.228733        0.014231   \n",
       "7       32.925288      0.803520         0.275194        0.019738   \n",
       "8       20.539478      0.770111         0.187956        0.015640   \n",
       "9       36.737521      4.823608         0.323245        0.004393   \n",
       "10      50.733952      2.882164         0.382448        0.010117   \n",
       "11      60.999094      5.021282         0.452244        0.007197   \n",
       "12      38.479821      0.052863         0.316802        0.007431   \n",
       "13      44.780118      0.420964         0.353218        0.006655   \n",
       "14      57.920039      4.530763         0.416654        0.014257   \n",
       "15      81.767273      3.730433         0.514749        0.015748   \n",
       "\n",
       "   param_kernel_size param_num_filters  \\\n",
       "0                  3                32   \n",
       "1                  3                64   \n",
       "2                  3               128   \n",
       "3                  3               256   \n",
       "4                  5                32   \n",
       "5                  5                64   \n",
       "6                  5               128   \n",
       "7                  5               256   \n",
       "8                  7                32   \n",
       "9                  7                64   \n",
       "10                 7               128   \n",
       "11                 7               256   \n",
       "12                 9                32   \n",
       "13                 9                64   \n",
       "14                 9               128   \n",
       "15                 9               256   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "0    {'kernel_size': 3, 'num_filters': 32}           0.848138   \n",
       "1    {'kernel_size': 3, 'num_filters': 64}           0.848138   \n",
       "2   {'kernel_size': 3, 'num_filters': 128}           0.848138   \n",
       "3   {'kernel_size': 3, 'num_filters': 256}           0.848138   \n",
       "4    {'kernel_size': 5, 'num_filters': 32}           0.848138   \n",
       "5    {'kernel_size': 5, 'num_filters': 64}           0.848138   \n",
       "6   {'kernel_size': 5, 'num_filters': 128}           0.848138   \n",
       "7   {'kernel_size': 5, 'num_filters': 256}           0.848138   \n",
       "8    {'kernel_size': 7, 'num_filters': 32}           0.848138   \n",
       "9    {'kernel_size': 7, 'num_filters': 64}           0.848138   \n",
       "10  {'kernel_size': 7, 'num_filters': 128}           0.848138   \n",
       "11  {'kernel_size': 7, 'num_filters': 256}           0.848138   \n",
       "12   {'kernel_size': 9, 'num_filters': 32}           0.848138   \n",
       "13   {'kernel_size': 9, 'num_filters': 64}           0.848138   \n",
       "14  {'kernel_size': 9, 'num_filters': 128}           0.848138   \n",
       "15  {'kernel_size': 9, 'num_filters': 256}           0.848138   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.868006           0.853659           0.860832   \n",
       "1            0.868006           0.853659           0.860832   \n",
       "2            0.868006           0.853659           0.860832   \n",
       "3            0.868006           0.853659           0.860832   \n",
       "4            0.868006           0.853659           0.860832   \n",
       "5            0.868006           0.853659           0.860832   \n",
       "6            0.868006           0.853659           0.860832   \n",
       "7            0.868006           0.853659           0.860832   \n",
       "8            0.868006           0.853659           0.860832   \n",
       "9            0.868006           0.853659           0.860832   \n",
       "10           0.868006           0.853659           0.860832   \n",
       "11           0.868006           0.853659           0.860832   \n",
       "12           0.868006           0.853659           0.860832   \n",
       "13           0.868006           0.853659           0.860832   \n",
       "14           0.868006           0.853659           0.860832   \n",
       "15           0.868006           0.853659           0.860832   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.870875         0.860302        0.008527                1  \n",
       "1            0.870875         0.860302        0.008527                1  \n",
       "2            0.870875         0.860302        0.008527                1  \n",
       "3            0.870875         0.860302        0.008527                1  \n",
       "4            0.870875         0.860302        0.008527                1  \n",
       "5            0.870875         0.860302        0.008527                1  \n",
       "6            0.870875         0.860302        0.008527                1  \n",
       "7            0.870875         0.860302        0.008527                1  \n",
       "8            0.870875         0.860302        0.008527                1  \n",
       "9            0.870875         0.860302        0.008527                1  \n",
       "10           0.870875         0.860302        0.008527                1  \n",
       "11           0.870875         0.860302        0.008527                1  \n",
       "12           0.870875         0.860302        0.008527                1  \n",
       "13           0.870875         0.860302        0.008527                1  \n",
       "14           0.870875         0.860302        0.008527                1  \n",
       "15           0.870875         0.860302        0.008527                1  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e100eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c432d5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9282639885222381\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score: {}\".format(f1_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f3f8cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score: {}\".format(recall_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3dd4b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8661311914323963\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score: {}\".format(precision_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb252f",
   "metadata": {},
   "source": [
    "Apresenta uma pequena melhora quando comparado com as metricas de com Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed14f5f",
   "metadata": {},
   "source": [
    "# Aplicando LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "20004fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 100)          498100    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 624,360\n",
      "Trainable params: 126,260\n",
      "Non-trainable params: 498,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "model2.add(embedding_layer)\n",
    "\n",
    "model2.add(LSTM(100, input_shape=(100,), activation='tanh'))\n",
    "\n",
    "model2.add(Dense(200, activation='relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(100, activation = \"relu\"))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(50, activation = \"relu\"))\n",
    "\n",
    "model2.add(Dense(10, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "79b164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"sparse_categorical_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "503f6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "349/349 [==============================] - 24s 63ms/step - loss: 2.0449 - accuracy: 0.8580 - val_loss: 1.7987 - val_accuracy: 0.8661\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 21s 62ms/step - loss: 1.5908 - accuracy: 0.8603 - val_loss: 1.3928 - val_accuracy: 0.8661\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 21s 61ms/step - loss: 1.2375 - accuracy: 0.8603 - val_loss: 1.0881 - val_accuracy: 0.8661\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 21s 60ms/step - loss: 0.9822 - accuracy: 0.8603 - val_loss: 0.8760 - val_accuracy: 0.8661\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 21s 61ms/step - loss: 0.8080 - accuracy: 0.8603 - val_loss: 0.7337 - val_accuracy: 0.8661\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 21s 61ms/step - loss: 0.6928 - accuracy: 0.8603 - val_loss: 0.6402 - val_accuracy: 0.8661\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 21s 60ms/step - loss: 0.6169 - accuracy: 0.8603 - val_loss: 0.5777 - val_accuracy: 0.8661\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 21s 61ms/step - loss: 0.5658 - accuracy: 0.8603 - val_loss: 0.5354 - val_accuracy: 0.8661\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 21s 60ms/step - loss: 0.5302 - accuracy: 0.8603 - val_loss: 0.5051 - val_accuracy: 0.8661\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 21s 61ms/step - loss: 0.5047 - accuracy: 0.8603 - val_loss: 0.4832 - val_accuracy: 0.8661\n"
     ]
    }
   ],
   "source": [
    "results = model2.fit(\n",
    " X_train_tensor, y_train,\n",
    " epochs= 10,\n",
    " batch_size = 10,\n",
    " validation_data = (X_test_tensor, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d5ebc2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 31ms/step - loss: 0.4832 - accuracy: 0.8661\n",
      "Testing Accuracy is 86.61311864852905 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test_tensor,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2811a83",
   "metadata": {},
   "source": [
    "## Tunning de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e59ce487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_optimize_lstm(units):\n",
    "    model = Sequential([\n",
    "      embedding_layer,\n",
    "      LSTM(units, input_shape=(100,), activation='tanh'),\n",
    "      Dense(200, activation='relu'),\n",
    "      Dropout(0.3),\n",
    "      Dense(100, activation = \"relu\"),\n",
    "      Dropout(0.3),\n",
    "      Dense(50, activation = \"relu\"),\n",
    "      Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "582b0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    \"units\": [100, 200, 300],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b5a01d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-196-07c587a702e1>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model2 = KerasClassifier(build_fn=model_to_optimize_lstm,\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model2 = KerasClassifier(build_fn=model_to_optimize_lstm,\n",
    "                        epochs=10,\n",
    "                        batch_size=10,\n",
    "                        verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4bb9fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridSearch2 = GridSearchCV(estimator=model2, param_grid=params2,\n",
    "                              cv=5, verbose=1)\n",
    "search_result = gridSearch2.fit(X_train_tensor, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "158f0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = gridSearch2.score(X_test_tensor, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d37aea08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8661311864852905"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "242ae088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 100}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e9dd1514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_units</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.452079</td>\n",
       "      <td>4.787409</td>\n",
       "      <td>1.364847</td>\n",
       "      <td>0.059301</td>\n",
       "      <td>100</td>\n",
       "      <td>{'units': 100}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232.264639</td>\n",
       "      <td>48.579821</td>\n",
       "      <td>2.704516</td>\n",
       "      <td>0.451689</td>\n",
       "      <td>200</td>\n",
       "      <td>{'units': 200}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363.454319</td>\n",
       "      <td>133.113097</td>\n",
       "      <td>2.269261</td>\n",
       "      <td>0.867435</td>\n",
       "      <td>300</td>\n",
       "      <td>{'units': 300}</td>\n",
       "      <td>0.848138</td>\n",
       "      <td>0.868006</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_units  \\\n",
       "0     138.452079      4.787409         1.364847        0.059301         100   \n",
       "1     232.264639     48.579821         2.704516        0.451689         200   \n",
       "2     363.454319    133.113097         2.269261        0.867435         300   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'units': 100}           0.848138           0.868006           0.853659   \n",
       "1  {'units': 200}           0.848138           0.868006           0.853659   \n",
       "2  {'units': 300}           0.848138           0.868006           0.853659   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.860832           0.870875         0.860302        0.008527   \n",
       "1           0.860832           0.870875         0.860302        0.008527   \n",
       "2           0.860832           0.870875         0.860302        0.008527   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridSearch2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e3b192c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9282639885222381\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score: {}\".format(f1_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3a954d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score: {}\".format(recall_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ba696a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8661311914323963\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score: {}\".format(precision_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
