{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a052cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4311caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Alexa3Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01083ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37ce508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date  \n",
       "0    9 de outubro de 2019  \n",
       "1    8 de outubro de 2019  \n",
       "2    8 de outubro de 2019  \n",
       "3  13 de novembro de 2019  \n",
       "4   23 de outubro de 2019  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2321b8",
   "metadata": {},
   "source": [
    "## Distribuicao das Avaliacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b992d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per star rating:\n",
      "5    3475\n",
      "4     818\n",
      "3     304\n",
      "1     233\n",
      "2     150\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df['rating'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(df['rating']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d884c",
   "metadata": {},
   "source": [
    "## Tokenizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44ec2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in a:\\anaconda3\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in a:\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in a:\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in a:\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in a:\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in a:\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in a:\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in a:\\anaconda3\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in a:\\anaconda3\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: numpy>=1.15.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: setuptools in a:\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in a:\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in a:\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in a:\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in a:\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in a:\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in a:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in a:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in a:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in a:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in a:\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in a:\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd2b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in a:\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: regex in a:\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in a:\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in a:\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in a:\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8affefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyStemmer\n",
      "  Using cached PyStemmer-2.0.1.tar.gz (559 kB)\n",
      "Building wheels for collected packages: PyStemmer\n",
      "  Building wheel for PyStemmer (setup.py): started\n",
      "  Building wheel for PyStemmer (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for PyStemmer\n",
      "Failed to build PyStemmer\n",
      "Installing collected packages: PyStemmer\n",
      "    Running setup.py install for PyStemmer: started\n",
      "    Running setup.py install for PyStemmer: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'A:\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-wheel-lt13tpk2'\n",
      "       cwd: C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-install-rfxawbgp\\pystemmer_6964043acff64aeca8439acc1676b864\\\n",
      "  Complete output (8 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  cythoning src/Stemmer.pyx to src\\Stemmer.c\n",
      "  A:\\anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-install-rfxawbgp\\pystemmer_6964043acff64aeca8439acc1676b864\\src\\Stemmer.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'Stemmer' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for PyStemmer\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'A:\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-record-1avh1w3i\\install-record.txt' --single-version-externally-managed --compile --install-headers 'A:\\anaconda3\\Include\\PyStemmer'\n",
      "         cwd: C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-install-rfxawbgp\\pystemmer_6964043acff64aeca8439acc1676b864\\\n",
      "    Complete output (6 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    skipping 'src\\Stemmer.c' Cython extension (up-to-date)\n",
      "    building 'Stemmer' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'A:\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Tuby Neto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rfxawbgp\\\\pystemmer_6964043acff64aeca8439acc1676b864\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Tuby Neto\\AppData\\Local\\Temp\\pip-record-1avh1w3i\\install-record.txt' --single-version-externally-managed --compile --install-headers 'A:\\anaconda3\\Include\\PyStemmer' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install PyStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "# É necessário instalar o pacote da lingua portuguesa no prompt do anaconda\n",
    "\n",
    "nlp = Portuguese()\n",
    "tokenizer = nlp.tokenizer\n",
    "text_token = []\n",
    "\n",
    "for line in df['text']: \n",
    "    tokens = tokenizer(line)\n",
    "    text_token.append(list(tokens))\n",
    "    \n",
    "df[\"text_token\"] = text_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8363911c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>[Sobre, o, produto, :, visual, muito, bonito, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[O, dispositivo, possui, 4, microfones, direci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[Comprei, o, Alexa, Echo, Dot, (, terceira, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>[Ainda, estou, me, adaptando, com, o, Echo, Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>[Acho, que, a, propaganda, desse, produto, est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \n",
       "0    9 de outubro de 2019  [Sobre, o, produto, :, visual, muito, bonito, ...  \n",
       "1    8 de outubro de 2019  [O, dispositivo, possui, 4, microfones, direci...  \n",
       "2    8 de outubro de 2019  [Comprei, o, Alexa, Echo, Dot, (, terceira, ge...  \n",
       "3  13 de novembro de 2019  [Ainda, estou, me, adaptando, com, o, Echo, Do...  \n",
       "4   23 de outubro de 2019  [Acho, que, a, propaganda, desse, produto, est...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4797734",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae9e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, nltk\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "\n",
    "stemmer = RSLPStemmer()\n",
    "\n",
    "stem_token_text = []\n",
    "\n",
    "for doc in text_token:\n",
    "    stem_list = []\n",
    "    for tkn in doc:\n",
    "        stem = stemmer.stem(str(tkn))\n",
    "        stem_list.append(stem)\n",
    "    stem_token_text.append(stem_list)\n",
    "df['Stem_teken_text'] = stem_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4659ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>[Sobre, o, produto, :, visual, muito, bonito, ...</td>\n",
       "      <td>[sobr, o, produt, :, visual, muit, bonit, e, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[O, dispositivo, possui, 4, microfones, direci...</td>\n",
       "      <td>[o, disposi, possu, 4, microfon, direc, do, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>[Comprei, o, Alexa, Echo, Dot, (, terceira, ge...</td>\n",
       "      <td>[compr, o, alex, ech, dot, (, terc, ger, ), as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>[Ainda, estou, me, adaptando, com, o, Echo, Do...</td>\n",
       "      <td>[aind, est, me, adapt, com, o, ech, dot, ., fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>[Acho, que, a, propaganda, desse, produto, est...</td>\n",
       "      <td>[ach, que, a, propagand, dess, produt, est, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  [Sobre, o, produto, :, visual, muito, bonito, ...   \n",
       "1    8 de outubro de 2019  [O, dispositivo, possui, 4, microfones, direci...   \n",
       "2    8 de outubro de 2019  [Comprei, o, Alexa, Echo, Dot, (, terceira, ge...   \n",
       "3  13 de novembro de 2019  [Ainda, estou, me, adaptando, com, o, Echo, Do...   \n",
       "4   23 de outubro de 2019  [Acho, que, a, propaganda, desse, produto, est...   \n",
       "\n",
       "                                     Stem_teken_text  \n",
       "0  [sobr, o, produt, :, visual, muit, bonit, e, b...  \n",
       "1  [o, disposi, possu, 4, microfon, direc, do, to...  \n",
       "2  [compr, o, alex, ech, dot, (, terc, ger, ), as...  \n",
       "3  [aind, est, me, adapt, com, o, ech, dot, ., fi...  \n",
       "4  [ach, que, a, propagand, dess, produt, est, se...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9a25f",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b2d3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ec5d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-6ac7513d89a9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Stem_teken_text\"][i] = \", \".join([str(item) for item in df[\"Stem_teken_text\"][i]])\n",
      "<ipython-input-14-6ac7513d89a9>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_token\"][i] = \", \".join([str(item) for item in df[\"text_token\"][i]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       Sobre, o, produto, :, visual, muito, bonito, e...\n",
       "1       O, dispositivo, possui, 4, microfones, direcio...\n",
       "2       Comprei, o, Alexa, Echo, Dot, (, terceira, ger...\n",
       "3       Ainda, estou, me, adaptando, com, o, Echo, Dot...\n",
       "4       Acho, que, a, propaganda, desse, produto, está...\n",
       "                              ...                        \n",
       "4975    Quería, muito, uma, caixa, de, som, para, ouvi...\n",
       "4976    Muito, bom, ,, melhor, ainda, do, que, eu, pen...\n",
       "4977    O, que, mais, gostei, ,, é, a, qualidade, de, ...\n",
       "4978    Muito, boa, ,, reconhece, muito, bem, a, voz, ...\n",
       "4979    Ótimo, produto, ,, desperta, ,, acende, a, lâm...\n",
       "Name: text_token, Length: 4980, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df[\"Stem_teken_text\"])):\n",
    "    df[\"Stem_teken_text\"][i] = \", \".join([str(item) for item in df[\"Stem_teken_text\"][i]])\n",
    "\n",
    "df[\"Stem_teken_text\"]\n",
    "\n",
    "for i in range(len(df[\"text_token\"])):\n",
    "    df[\"text_token\"][i] = \", \".join([str(item) for item in df[\"text_token\"][i]])\n",
    "\n",
    "df[\"text_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00bbb5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1    8 de outubro de 2019  O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2    8 de outubro de 2019  Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3  13 de novembro de 2019  Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4   23 de outubro de 2019  Acho, que, a, propaganda, desse, produto, está...   \n",
       "\n",
       "                                     Stem_teken_text  \n",
       "0  sobr, o, produt, :, visual, muit, bonit, e, be...  \n",
       "1  o, disposi, possu, 4, microfon, direc, do, top...  \n",
       "2  compr, o, alex, ech, dot, (, terc, ger, ), ass...  \n",
       "3  aind, est, me, adapt, com, o, ech, dot, ., fiz...  \n",
       "4  ach, que, a, propagand, dess, produt, est, sen...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a709a",
   "metadata": {},
   "source": [
    "# Com Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2cdf7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4980x6422 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 217762 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsTexts = list(df[\"Stem_teken_text\"])\n",
    "countVectorizer = CountVectorizer(binary=True, ngram_range = (1,1))\n",
    "bowTransformer = countVectorizer.fit(reviewsTexts)\n",
    "reviewsTexts = bowTransformer.transform(reviewsTexts)\n",
    "\n",
    "reviewsTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb161e",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae8c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviewsTexts, df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0061d6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce004ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 3.30205321,  6.71390777,  9.47268014, 12.47578883, 15.10138898,\n",
       "        20.55891547, 29.24189572,  4.37630992,  8.04925199, 11.47303128,\n",
       "        11.99137325, 15.57357421, 22.59526939, 20.03773284]),\n",
       " 'std_fit_time': array([0.21408367, 0.45013937, 0.5501417 , 0.57496657, 0.27340829,\n",
       "        2.73222569, 2.51284929, 0.42352395, 1.20739893, 1.03451076,\n",
       "        0.73215071, 0.7744524 , 1.11529363, 3.38956361]),\n",
       " 'mean_score_time': array([0.04339976, 0.08852673, 0.11799974, 0.16011963, 0.29620099,\n",
       "        0.30822072, 0.47963247, 0.07243671, 0.09884377, 0.13592591,\n",
       "        0.15801182, 0.23023229, 0.26262221, 0.17410274]),\n",
       " 'std_score_time': array([0.00637479, 0.01023326, 0.0098183 , 0.03066687, 0.06031751,\n",
       "        0.03482097, 0.10106873, 0.02417488, 0.03239706, 0.04684141,\n",
       "        0.02809088, 0.05920389, 0.03055755, 0.03412116]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 250, 300, 350, 50, 100, 150, 200,\n",
       "                    250, 300, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'n_estimators': 50},\n",
       "  {'criterion': 'gini', 'n_estimators': 100},\n",
       "  {'criterion': 'gini', 'n_estimators': 150},\n",
       "  {'criterion': 'gini', 'n_estimators': 200},\n",
       "  {'criterion': 'gini', 'n_estimators': 250},\n",
       "  {'criterion': 'gini', 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'n_estimators': 350},\n",
       "  {'criterion': 'entropy', 'n_estimators': 50},\n",
       "  {'criterion': 'entropy', 'n_estimators': 100},\n",
       "  {'criterion': 'entropy', 'n_estimators': 150},\n",
       "  {'criterion': 'entropy', 'n_estimators': 200},\n",
       "  {'criterion': 'entropy', 'n_estimators': 250},\n",
       "  {'criterion': 'entropy', 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'n_estimators': 350}],\n",
       " 'split0_test_f1_micro': array([0.70057307, 0.70630372, 0.70487106, 0.70057307, 0.70057307,\n",
       "        0.70487106, 0.7034384 , 0.70487106, 0.70200573, 0.70200573,\n",
       "        0.70200573, 0.70200573, 0.70200573, 0.70200573]),\n",
       " 'split1_test_f1_micro': array([0.70301291, 0.70301291, 0.70157819, 0.70444763, 0.70301291,\n",
       "        0.70157819, 0.70301291, 0.70157819, 0.70301291, 0.70301291,\n",
       "        0.70301291, 0.70301291, 0.70301291, 0.70301291]),\n",
       " 'split2_test_f1_micro': array([0.70157819, 0.70157819, 0.70157819, 0.70014347, 0.70157819,\n",
       "        0.70157819, 0.70157819, 0.70157819, 0.70157819, 0.70157819,\n",
       "        0.70157819, 0.70157819, 0.70157819, 0.70157819]),\n",
       " 'split3_test_f1_micro': array([0.70444763, 0.70014347, 0.70301291, 0.70301291, 0.70444763,\n",
       "        0.70157819, 0.70157819, 0.70444763, 0.70157819, 0.70157819,\n",
       "        0.70157819, 0.70157819, 0.70157819, 0.70157819]),\n",
       " 'split4_test_f1_micro': array([0.70444763, 0.70157819, 0.70588235, 0.70301291, 0.70301291,\n",
       "        0.70444763, 0.70301291, 0.70301291, 0.70301291, 0.70301291,\n",
       "        0.70301291, 0.70301291, 0.70301291, 0.70301291]),\n",
       " 'mean_test_f1_micro': array([0.70281189, 0.7025233 , 0.70338454, 0.702238  , 0.70252494,\n",
       "        0.70281065, 0.70252412, 0.7030976 , 0.70223759, 0.70223759,\n",
       "        0.70223759, 0.70223759, 0.70223759, 0.70223759]),\n",
       " 'std_test_f1_micro': array([0.00154441, 0.00209673, 0.00173855, 0.00162742, 0.0013326 ,\n",
       "        0.00151538, 0.00078782, 0.00138507, 0.00065202, 0.00065202,\n",
       "        0.00065202, 0.00065202, 0.00065202, 0.00065202]),\n",
       " 'rank_test_f1_micro': array([3, 7, 1, 8, 5, 4, 6, 2, 9, 9, 9, 9, 9, 9])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np \n",
    "\n",
    "scores = ['f1_micro']\n",
    "\n",
    "parameters = {\n",
    "     'n_estimators': list(range(50, 351, 50)),\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( RandomForestClassifier(), \n",
    "                            parameters,\n",
    "                            n_jobs = -1,    \n",
    "                            scoring = scores,\n",
    "                            cv = 5,\n",
    "                            refit = 'f1_micro', \n",
    "                            verbose=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438ca8e",
   "metadata": {},
   "source": [
    "## Melhores Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ac600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 150}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fe04f",
   "metadata": {},
   "source": [
    "## Testando o Modelo com os Parametros Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b7391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randomForest = RandomForestClassifier(criterion= grid_search.best_params_['criterion'], n_estimators = grid_search.best_params_['n_estimators']).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da32fff",
   "metadata": {},
   "source": [
    "## Metricas Obtidas sobre a Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6089fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.01      0.03        70\n",
      "           2       0.00      0.00      0.00        46\n",
      "           3       0.00      0.00      0.00        92\n",
      "           4       0.25      0.00      0.01       259\n",
      "           5       0.69      1.00      0.82      1027\n",
      "\n",
      "    accuracy                           0.69      1494\n",
      "   macro avg       0.39      0.20      0.17      1494\n",
      "weighted avg       0.56      0.69      0.56      1494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35d23266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880856760374833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, randomForest.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c7e5c",
   "metadata": {},
   "source": [
    "# Sem Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8b944ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4980x12202 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 227068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsTexts = list(df[\"text_token\"])\n",
    "countVectorizer = CountVectorizer(binary=True, ngram_range = (1,1))\n",
    "bowTransformer = countVectorizer.fit(reviewsTexts)\n",
    "reviewsTexts = bowTransformer.transform(reviewsTexts)\n",
    "\n",
    "reviewsTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a497ce",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff36ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviewsTexts, df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f2c80",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38ecce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 4.69450574,  9.51673446, 14.65537262, 20.80579209, 23.68739629,\n",
       "        26.97079587, 28.67561607,  3.98779831,  8.01560507, 12.08940802,\n",
       "        16.82657065, 21.21430144, 24.83658624, 22.22296638]),\n",
       " 'std_fit_time': array([0.66159318, 0.9969162 , 1.45880546, 1.97655028, 2.13791398,\n",
       "        2.06556238, 1.08272811, 0.11728232, 0.57183612, 0.46044183,\n",
       "        0.94043143, 1.01175757, 1.26646964, 3.01397713]),\n",
       " 'mean_score_time': array([0.05400314, 0.10402412, 0.16263962, 0.34154363, 0.26473923,\n",
       "        0.27057695, 0.40024724, 0.05130363, 0.07621307, 0.13905244,\n",
       "        0.21345186, 0.25130949, 0.26391172, 0.17441001]),\n",
       " 'std_score_time': array([0.01494216, 0.015167  , 0.02763673, 0.10258723, 0.03974841,\n",
       "        0.02653048, 0.12885425, 0.00829291, 0.00847498, 0.02440334,\n",
       "        0.05344013, 0.0537712 , 0.0345126 , 0.02621997]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 250, 300, 350, 50, 100, 150, 200,\n",
       "                    250, 300, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'n_estimators': 50},\n",
       "  {'criterion': 'gini', 'n_estimators': 100},\n",
       "  {'criterion': 'gini', 'n_estimators': 150},\n",
       "  {'criterion': 'gini', 'n_estimators': 200},\n",
       "  {'criterion': 'gini', 'n_estimators': 250},\n",
       "  {'criterion': 'gini', 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'n_estimators': 350},\n",
       "  {'criterion': 'entropy', 'n_estimators': 50},\n",
       "  {'criterion': 'entropy', 'n_estimators': 100},\n",
       "  {'criterion': 'entropy', 'n_estimators': 150},\n",
       "  {'criterion': 'entropy', 'n_estimators': 200},\n",
       "  {'criterion': 'entropy', 'n_estimators': 250},\n",
       "  {'criterion': 'entropy', 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'n_estimators': 350}],\n",
       " 'split0_test_f1_micro': array([0.6991404 , 0.6991404 , 0.70200573, 0.69770774, 0.69770774,\n",
       "        0.69627507, 0.69627507, 0.6991404 , 0.69627507, 0.69770774,\n",
       "        0.69770774, 0.69770774, 0.69770774, 0.69770774]),\n",
       " 'split1_test_f1_micro': array([0.69727403, 0.69727403, 0.69870875, 0.69870875, 0.69870875,\n",
       "        0.70014347, 0.69870875, 0.69870875, 0.69870875, 0.69870875,\n",
       "        0.69870875, 0.69870875, 0.69870875, 0.69870875]),\n",
       " 'split2_test_f1_micro': array([0.70444763, 0.70301291, 0.70014347, 0.70444763, 0.70444763,\n",
       "        0.70157819, 0.69870875, 0.69870875, 0.70014347, 0.70014347,\n",
       "        0.70014347, 0.70014347, 0.69870875, 0.69870875]),\n",
       " 'split3_test_f1_micro': array([0.69440459, 0.69583931, 0.69583931, 0.69727403, 0.69727403,\n",
       "        0.69440459, 0.69583931, 0.69583931, 0.69440459, 0.69727403,\n",
       "        0.69727403, 0.69727403, 0.69727403, 0.69727403]),\n",
       " 'split4_test_f1_micro': array([0.69296987, 0.69583931, 0.69440459, 0.69727403, 0.69583931,\n",
       "        0.69440459, 0.69583931, 0.69440459, 0.69727403, 0.69727403,\n",
       "        0.69727403, 0.69727403, 0.69727403, 0.69727403]),\n",
       " 'mean_test_f1_micro': array([0.69764731, 0.69822119, 0.69822037, 0.69908244, 0.69879549,\n",
       "        0.69736118, 0.69707424, 0.69736036, 0.69736118, 0.6982216 ,\n",
       "        0.6982216 , 0.6982216 , 0.69793466, 0.69793466]),\n",
       " 'std_test_f1_micro': array([0.00402509, 0.00268512, 0.00277472, 0.00273333, 0.00297292,\n",
       "        0.00297277, 0.00134403, 0.00188971, 0.00197412, 0.0010946 ,\n",
       "        0.0010946 , 0.0010946 , 0.00065158, 0.00065158]),\n",
       " 'rank_test_f1_micro': array([10,  6,  7,  1,  2, 11, 14, 13, 11,  3,  3,  3,  8,  8])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np \n",
    "\n",
    "scores = ['f1_micro']\n",
    "\n",
    "parameters = {\n",
    "     'n_estimators': list(range(50, 351, 50)),\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( RandomForestClassifier(), \n",
    "                            parameters,\n",
    "                            n_jobs = -1,    \n",
    "                            scoring = scores,\n",
    "                            cv = 5,\n",
    "                            refit = 'f1_micro', \n",
    "                            verbose=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d56d01",
   "metadata": {},
   "source": [
    "## Melhores Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbe3e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 200}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1c151",
   "metadata": {},
   "source": [
    "## Testando o Modelo com os Parametros Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815661cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randomForest = RandomForestClassifier(criterion= grid_search.best_params_['criterion'], n_estimators = grid_search.best_params_['n_estimators']).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f60ce6",
   "metadata": {},
   "source": [
    "## Metricas Obtidas sobre a Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ebaf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.03      0.06        63\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00        99\n",
      "           4       0.33      0.00      0.01       230\n",
      "           5       0.70      1.00      0.82      1042\n",
      "\n",
      "    accuracy                           0.70      1494\n",
      "   macro avg       0.41      0.21      0.18      1494\n",
      "weighted avg       0.58      0.70      0.58      1494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "A:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b64577b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987951807228916"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, randomForest.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11d812",
   "metadata": {},
   "source": [
    "Apos a execucao sem e com stemming, obteve-se um f1-score ligeiramente melhor com o stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1cf2c8",
   "metadata": {},
   "source": [
    "# Aplicacao da CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23006a",
   "metadata": {},
   "source": [
    " ## Consultando o Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4dfc4a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       sobr, o, produt, :, visual, muit, bonit, e, be...\n",
       "1       o, disposi, possu, 4, microfon, direc, do, top...\n",
       "2       compr, o, alex, ech, dot, (, terc, ger, ), ass...\n",
       "3       aind, est, me, adapt, com, o, ech, dot, ., fiz...\n",
       "4       ach, que, a, propagand, dess, produt, est, sen...\n",
       "                              ...                        \n",
       "4975    querí, muit, uma, caix, de, som, par, ouv, min...\n",
       "4976    muit, bom, ,, melhor, aind, do, que, eu, pens,...\n",
       "4977    o, que, mais, gost, ,, é, a, qual, de, áudi, ,...\n",
       "4978    muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...\n",
       "4979    ótim, produt, ,, despert, ,, acend, a, lâmp, ,...\n",
       "Name: Stem_teken_text, Length: 4980, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Stem_teken_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abd15434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho do vocabulário é:  4979\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "word_count = Counter()\n",
    "for token in list(df['Stem_teken_text']): \n",
    "    word_count[token] += 1\n",
    "\n",
    "word_count\n",
    "vocabSize = len(word_count)\n",
    "\n",
    "print(\"O tamanho do vocabulário é: \", vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9c0b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = vocabSize\n",
    "oov_token = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(df['Stem_teken_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe6cd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_to_sequence\"] = tokenizer.texts_to_sequences(df['Stem_teken_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfbabf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in a:\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in a:\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in a:\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in a:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in a:\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in a:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in a:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in a:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in a:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in a:\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in a:\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in a:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in a:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in a:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in a:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in a:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d21326",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd901157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 100\n",
    "padding_type = \"post\"\n",
    "trunction_type=\"post\"\n",
    "text_to_sequence_padded = pad_sequences(df[\"text_to_sequence\"], maxlen=max_length, padding=padding_type,\n",
    "                       truncating=trunction_type)\n",
    "df[\"text_to_sequence_padded\"] = list(text_to_sequence_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3cb2ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "      <th>text_to_sequence</th>\n",
       "      <th>text_to_sequence_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                   Excelente custo benefício   \n",
       "1  Péssimo início - defeito ao tirar da caixa   \n",
       "2                          Excelente produto!   \n",
       "3                            Muito Satisfeito   \n",
       "4                Decepção é o meu sentimento.   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1  O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2  Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3  Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4  Acho que a propaganda desse produto está sendo...       1   \n",
       "\n",
       "                     date                                         text_token  \\\n",
       "0    9 de outubro de 2019  Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1    8 de outubro de 2019  O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2    8 de outubro de 2019  Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3  13 de novembro de 2019  Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4   23 de outubro de 2019  Acho, que, a, propaganda, desse, produto, está...   \n",
       "\n",
       "                                     Stem_teken_text  \\\n",
       "0  sobr, o, produt, :, visual, muit, bonit, e, be...   \n",
       "1  o, disposi, possu, 4, microfon, direc, do, top...   \n",
       "2  compr, o, alex, ech, dot, (, terc, ger, ), ass...   \n",
       "3  aind, est, me, adapt, com, o, ech, dot, ., fiz...   \n",
       "4  ach, que, a, propagand, dess, produt, est, sen...   \n",
       "\n",
       "                                    text_to_sequence  \\\n",
       "0  [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...   \n",
       "1  [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...   \n",
       "2  [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...   \n",
       "3  [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...   \n",
       "4  [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...   \n",
       "\n",
       "                             text_to_sequence_padded  \n",
       "0  [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...  \n",
       "1  [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...  \n",
       "2  [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...  \n",
       "3  [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...  \n",
       "4  [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d4f435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_to_sequence_padded'] , df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f511e63",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c4ac770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 929593 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)  \n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove_s100.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    \n",
    "    coefs = []\n",
    "    for coef in values[1:]:\n",
    "        if (is_float(coef)):\n",
    "            coefs.append(coef)\n",
    "    \n",
    "    coefs = np.asarray(coefs, dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72ca61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "\n",
    "for i, word in enumerate(list(word_count.keys())):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if (embedding_vector is not None):\n",
    "        embedding_dict[word] = embedding_vector\n",
    "    else:\n",
    "        embedding_dict[word] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bd1e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_count) + 1, 100))\n",
    "\n",
    "\n",
    "for i, word in enumerate(list(word_count.keys())):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f61fbbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c65e8",
   "metadata": {},
   "source": [
    "## Criando a Camada de Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7d87886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(input_dim=len(word_count) + 1,\n",
    "                            output_dim=100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=100,\n",
    "                            trainable=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fef804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea11d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f1a6b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "      <th>text_to_sequence</th>\n",
       "      <th>text_to_sequence_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>5</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>MELHOR COMPRA DA MINHA VIDA</td>\n",
       "      <td>Quería muito uma caixa de som para ouvir minha...</td>\n",
       "      <td>5</td>\n",
       "      <td>25 de novembro de 2020</td>\n",
       "      <td>Quería, muito, uma, caixa, de, som, para, ouvi...</td>\n",
       "      <td>querí, muit, uma, caix, de, som, par, ouv, min...</td>\n",
       "      <td>[1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...</td>\n",
       "      <td>[1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>SUPIMPA!!!!</td>\n",
       "      <td>Muito bom, melhor ainda do que eu pense, apena...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 de dezembro de 2020</td>\n",
       "      <td>Muito, bom, ,, melhor, ainda, do, que, eu, pen...</td>\n",
       "      <td>muit, bom, ,, melhor, aind, do, que, eu, pens,...</td>\n",
       "      <td>[11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...</td>\n",
       "      <td>[11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>A melhor</td>\n",
       "      <td>O que mais gostei, é a qualidade de áudio, vol...</td>\n",
       "      <td>5</td>\n",
       "      <td>17 de junho de 2021</td>\n",
       "      <td>O, que, mais, gostei, ,, é, a, qualidade, de, ...</td>\n",
       "      <td>o, que, mais, gost, ,, é, a, qual, de, áudi, ,...</td>\n",
       "      <td>[5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...</td>\n",
       "      <td>[5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>A Alexa compensa muito comprar.</td>\n",
       "      <td>Muito boa, reconhece muito bem a voz , o volum...</td>\n",
       "      <td>5</td>\n",
       "      <td>12 de agosto de 2020</td>\n",
       "      <td>Muito, boa, ,, reconhece, muito, bem, a, voz, ...</td>\n",
       "      <td>muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...</td>\n",
       "      <td>[11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...</td>\n",
       "      <td>[11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Muito satisfeito</td>\n",
       "      <td>Ótimo produto, desperta, acende a lâmpada, toc...</td>\n",
       "      <td>5</td>\n",
       "      <td>8 de janeiro de 2021</td>\n",
       "      <td>Ótimo, produto, ,, desperta, ,, acende, a, lâm...</td>\n",
       "      <td>ótim, produt, ,, despert, ,, acend, a, lâmp, ,...</td>\n",
       "      <td>[64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...</td>\n",
       "      <td>[64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4980 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                      Excelente custo benefício   \n",
       "1     Péssimo início - defeito ao tirar da caixa   \n",
       "2                             Excelente produto!   \n",
       "3                               Muito Satisfeito   \n",
       "4                   Decepção é o meu sentimento.   \n",
       "...                                          ...   \n",
       "4975                 MELHOR COMPRA DA MINHA VIDA   \n",
       "4976                                 SUPIMPA!!!!   \n",
       "4977                                    A melhor   \n",
       "4978             A Alexa compensa muito comprar.   \n",
       "4979                            Muito satisfeito   \n",
       "\n",
       "                                                   text  rating  \\\n",
       "0     Sobre o produto: visual muito bonito e bem aca...       5   \n",
       "1     O dispositivo possui 4 microfones direcionais ...       1   \n",
       "2     Comprei o Alexa Echo Dot (terceira geração) as...       5   \n",
       "3     Ainda estou me adaptando com o Echo Dot.Fiz a ...       5   \n",
       "4     Acho que a propaganda desse produto está sendo...       1   \n",
       "...                                                 ...     ...   \n",
       "4975  Quería muito uma caixa de som para ouvir minha...       5   \n",
       "4976  Muito bom, melhor ainda do que eu pense, apena...       5   \n",
       "4977  O que mais gostei, é a qualidade de áudio, vol...       5   \n",
       "4978  Muito boa, reconhece muito bem a voz , o volum...       5   \n",
       "4979  Ótimo produto, desperta, acende a lâmpada, toc...       5   \n",
       "\n",
       "                        date  \\\n",
       "0       9 de outubro de 2019   \n",
       "1       8 de outubro de 2019   \n",
       "2       8 de outubro de 2019   \n",
       "3     13 de novembro de 2019   \n",
       "4      23 de outubro de 2019   \n",
       "...                      ...   \n",
       "4975  25 de novembro de 2020   \n",
       "4976   1 de dezembro de 2020   \n",
       "4977     17 de junho de 2021   \n",
       "4978    12 de agosto de 2020   \n",
       "4979    8 de janeiro de 2021   \n",
       "\n",
       "                                             text_token  \\\n",
       "0     Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1     O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2     Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3     Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4     Acho, que, a, propaganda, desse, produto, está...   \n",
       "...                                                 ...   \n",
       "4975  Quería, muito, uma, caixa, de, som, para, ouvi...   \n",
       "4976  Muito, bom, ,, melhor, ainda, do, que, eu, pen...   \n",
       "4977  O, que, mais, gostei, ,, é, a, qualidade, de, ...   \n",
       "4978  Muito, boa, ,, reconhece, muito, bem, a, voz, ...   \n",
       "4979  Ótimo, produto, ,, desperta, ,, acende, a, lâm...   \n",
       "\n",
       "                                        Stem_teken_text  \\\n",
       "0     sobr, o, produt, :, visual, muit, bonit, e, be...   \n",
       "1     o, disposi, possu, 4, microfon, direc, do, top...   \n",
       "2     compr, o, alex, ech, dot, (, terc, ger, ), ass...   \n",
       "3     aind, est, me, adapt, com, o, ech, dot, ., fiz...   \n",
       "4     ach, que, a, propagand, dess, produt, est, sen...   \n",
       "...                                                 ...   \n",
       "4975  querí, muit, uma, caix, de, som, par, ouv, min...   \n",
       "4976  muit, bom, ,, melhor, aind, do, que, eu, pens,...   \n",
       "4977  o, que, mais, gost, ,, é, a, qual, de, áudi, ,...   \n",
       "4978  muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...   \n",
       "4979  ótim, produt, ,, despert, ,, acend, a, lâmp, ,...   \n",
       "\n",
       "                                       text_to_sequence  \\\n",
       "0     [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...   \n",
       "1     [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...   \n",
       "2     [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...   \n",
       "3     [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...   \n",
       "4     [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...   \n",
       "...                                                 ...   \n",
       "4975  [1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...   \n",
       "4976  [11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...   \n",
       "4977  [5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...   \n",
       "4978  [11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...   \n",
       "4979  [64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...   \n",
       "\n",
       "                                text_to_sequence_padded  \n",
       "0     [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...  \n",
       "1     [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...  \n",
       "2     [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...  \n",
       "3     [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...  \n",
       "4     [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...  \n",
       "...                                                 ...  \n",
       "4975  [1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...  \n",
       "4976  [11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...  \n",
       "4977  [5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...  \n",
       "4978  [11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...  \n",
       "4979  [64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...  \n",
       "\n",
       "[4980 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1432cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRatings = []\n",
    "\n",
    "for rating in df[\"rating\"]:\n",
    "    if rating==1 or rating==2 or rating==3:\n",
    "        newRatings.append(0)\n",
    "    else:\n",
    "        newRatings.append(1)\n",
    "        \n",
    "df[\"rating\"] = newRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8c7d371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Stem_teken_text</th>\n",
       "      <th>text_to_sequence</th>\n",
       "      <th>text_to_sequence_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excelente custo benefício</td>\n",
       "      <td>Sobre o produto: visual muito bonito e bem aca...</td>\n",
       "      <td>1</td>\n",
       "      <td>9 de outubro de 2019</td>\n",
       "      <td>Sobre, o, produto, :, visual, muito, bonito, e...</td>\n",
       "      <td>sobr, o, produt, :, visual, muit, bonit, e, be...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "      <td>[178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo início - defeito ao tirar da caixa</td>\n",
       "      <td>O dispositivo possui 4 microfones direcionais ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>O, dispositivo, possui, 4, microfones, direcio...</td>\n",
       "      <td>o, disposi, possu, 4, microfon, direc, do, top...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "      <td>[5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente produto!</td>\n",
       "      <td>Comprei o Alexa Echo Dot (terceira geração) as...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de outubro de 2019</td>\n",
       "      <td>Comprei, o, Alexa, Echo, Dot, (, terceira, ger...</td>\n",
       "      <td>compr, o, alex, ech, dot, (, terc, ger, ), ass...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "      <td>[24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito Satisfeito</td>\n",
       "      <td>Ainda estou me adaptando com o Echo Dot.Fiz a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "      <td>Ainda, estou, me, adaptando, com, o, Echo, Dot...</td>\n",
       "      <td>aind, est, me, adapt, com, o, ech, dot, ., fiz...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "      <td>[47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decepção é o meu sentimento.</td>\n",
       "      <td>Acho que a propaganda desse produto está sendo...</td>\n",
       "      <td>0</td>\n",
       "      <td>23 de outubro de 2019</td>\n",
       "      <td>Acho, que, a, propaganda, desse, produto, está...</td>\n",
       "      <td>ach, que, a, propagand, dess, produt, est, sen...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "      <td>[82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>MELHOR COMPRA DA MINHA VIDA</td>\n",
       "      <td>Quería muito uma caixa de som para ouvir minha...</td>\n",
       "      <td>1</td>\n",
       "      <td>25 de novembro de 2020</td>\n",
       "      <td>Quería, muito, uma, caixa, de, som, para, ouvi...</td>\n",
       "      <td>querí, muit, uma, caix, de, som, par, ouv, min...</td>\n",
       "      <td>[1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...</td>\n",
       "      <td>[1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>SUPIMPA!!!!</td>\n",
       "      <td>Muito bom, melhor ainda do que eu pense, apena...</td>\n",
       "      <td>1</td>\n",
       "      <td>1 de dezembro de 2020</td>\n",
       "      <td>Muito, bom, ,, melhor, ainda, do, que, eu, pen...</td>\n",
       "      <td>muit, bom, ,, melhor, aind, do, que, eu, pens,...</td>\n",
       "      <td>[11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...</td>\n",
       "      <td>[11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>A melhor</td>\n",
       "      <td>O que mais gostei, é a qualidade de áudio, vol...</td>\n",
       "      <td>1</td>\n",
       "      <td>17 de junho de 2021</td>\n",
       "      <td>O, que, mais, gostei, ,, é, a, qualidade, de, ...</td>\n",
       "      <td>o, que, mais, gost, ,, é, a, qual, de, áudi, ,...</td>\n",
       "      <td>[5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...</td>\n",
       "      <td>[5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>A Alexa compensa muito comprar.</td>\n",
       "      <td>Muito boa, reconhece muito bem a voz , o volum...</td>\n",
       "      <td>1</td>\n",
       "      <td>12 de agosto de 2020</td>\n",
       "      <td>Muito, boa, ,, reconhece, muito, bem, a, voz, ...</td>\n",
       "      <td>muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...</td>\n",
       "      <td>[11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...</td>\n",
       "      <td>[11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Muito satisfeito</td>\n",
       "      <td>Ótimo produto, desperta, acende a lâmpada, toc...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 de janeiro de 2021</td>\n",
       "      <td>Ótimo, produto, ,, desperta, ,, acende, a, lâm...</td>\n",
       "      <td>ótim, produt, ,, despert, ,, acend, a, lâmp, ,...</td>\n",
       "      <td>[64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...</td>\n",
       "      <td>[64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4980 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                      Excelente custo benefício   \n",
       "1     Péssimo início - defeito ao tirar da caixa   \n",
       "2                             Excelente produto!   \n",
       "3                               Muito Satisfeito   \n",
       "4                   Decepção é o meu sentimento.   \n",
       "...                                          ...   \n",
       "4975                 MELHOR COMPRA DA MINHA VIDA   \n",
       "4976                                 SUPIMPA!!!!   \n",
       "4977                                    A melhor   \n",
       "4978             A Alexa compensa muito comprar.   \n",
       "4979                            Muito satisfeito   \n",
       "\n",
       "                                                   text  rating  \\\n",
       "0     Sobre o produto: visual muito bonito e bem aca...       1   \n",
       "1     O dispositivo possui 4 microfones direcionais ...       0   \n",
       "2     Comprei o Alexa Echo Dot (terceira geração) as...       1   \n",
       "3     Ainda estou me adaptando com o Echo Dot.Fiz a ...       1   \n",
       "4     Acho que a propaganda desse produto está sendo...       0   \n",
       "...                                                 ...     ...   \n",
       "4975  Quería muito uma caixa de som para ouvir minha...       1   \n",
       "4976  Muito bom, melhor ainda do que eu pense, apena...       1   \n",
       "4977  O que mais gostei, é a qualidade de áudio, vol...       1   \n",
       "4978  Muito boa, reconhece muito bem a voz , o volum...       1   \n",
       "4979  Ótimo produto, desperta, acende a lâmpada, toc...       1   \n",
       "\n",
       "                        date  \\\n",
       "0       9 de outubro de 2019   \n",
       "1       8 de outubro de 2019   \n",
       "2       8 de outubro de 2019   \n",
       "3     13 de novembro de 2019   \n",
       "4      23 de outubro de 2019   \n",
       "...                      ...   \n",
       "4975  25 de novembro de 2020   \n",
       "4976   1 de dezembro de 2020   \n",
       "4977     17 de junho de 2021   \n",
       "4978    12 de agosto de 2020   \n",
       "4979    8 de janeiro de 2021   \n",
       "\n",
       "                                             text_token  \\\n",
       "0     Sobre, o, produto, :, visual, muito, bonito, e...   \n",
       "1     O, dispositivo, possui, 4, microfones, direcio...   \n",
       "2     Comprei, o, Alexa, Echo, Dot, (, terceira, ger...   \n",
       "3     Ainda, estou, me, adaptando, com, o, Echo, Dot...   \n",
       "4     Acho, que, a, propaganda, desse, produto, está...   \n",
       "...                                                 ...   \n",
       "4975  Quería, muito, uma, caixa, de, som, para, ouvi...   \n",
       "4976  Muito, bom, ,, melhor, ainda, do, que, eu, pen...   \n",
       "4977  O, que, mais, gostei, ,, é, a, qualidade, de, ...   \n",
       "4978  Muito, boa, ,, reconhece, muito, bem, a, voz, ...   \n",
       "4979  Ótimo, produto, ,, desperta, ,, acende, a, lâm...   \n",
       "\n",
       "                                        Stem_teken_text  \\\n",
       "0     sobr, o, produt, :, visual, muit, bonit, e, be...   \n",
       "1     o, disposi, possu, 4, microfon, direc, do, top...   \n",
       "2     compr, o, alex, ech, dot, (, terc, ger, ), ass...   \n",
       "3     aind, est, me, adapt, com, o, ech, dot, ., fiz...   \n",
       "4     ach, que, a, propagand, dess, produt, est, sen...   \n",
       "...                                                 ...   \n",
       "4975  querí, muit, uma, caix, de, som, par, ouv, min...   \n",
       "4976  muit, bom, ,, melhor, aind, do, que, eu, pens,...   \n",
       "4977  o, que, mais, gost, ,, é, a, qual, de, áudi, ,...   \n",
       "4978  muit, boa, ,, reconhec, muit, bem, a, voz, ,, ...   \n",
       "4979  ótim, produt, ,, despert, ,, acend, a, lâmp, ,...   \n",
       "\n",
       "                                       text_to_sequence  \\\n",
       "0     [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...   \n",
       "1     [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...   \n",
       "2     [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...   \n",
       "3     [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...   \n",
       "4     [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...   \n",
       "...                                                 ...   \n",
       "4975  [1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...   \n",
       "4976  [11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...   \n",
       "4977  [5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...   \n",
       "4978  [11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...   \n",
       "4979  [64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...   \n",
       "\n",
       "                                text_to_sequence_padded  \n",
       "0     [178, 5, 26, 862, 11, 346, 4, 30, 185, 616, 14...  \n",
       "1     [5, 74, 199, 250, 201, 1993, 12, 529, 470, 62,...  \n",
       "2     [24, 5, 18, 32, 49, 721, 167, 203, 6, 292, 160...  \n",
       "3     [47, 21, 42, 540, 7, 5, 32, 49, 274, 2, 334, 1...  \n",
       "4     [82, 6, 2, 963, 366, 26, 21, 231, 422, 3, 237,...  \n",
       "...                                                 ...  \n",
       "4975  [1, 11, 15, 76, 3, 19, 10, 73, 33, 103, 185, 2...  \n",
       "4976  [11, 48, 50, 47, 12, 6, 35, 242, 140, 126, 43,...  \n",
       "4977  [5, 6, 23, 61, 8, 2, 34, 3, 225, 119, 84, 9, 1...  \n",
       "4978  [11, 77, 45, 11, 30, 2, 31, 5, 119, 8, 11, 48,...  \n",
       "4979  [64, 26, 350, 480, 2, 179, 96, 38, 104, 8, 94,...  \n",
       "\n",
       "[4980 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00e86f",
   "metadata": {},
   "source": [
    "## Divisao da Base em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed6649d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_to_sequence_padded'], df['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92724bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3982    [18, 263, 225, 71, 555, 156, 117, 210, 12, 306...\n",
       "3219    [5, 747, 3, 97, 16, 18, 21, 70, 214, 44, 50, 2...\n",
       "1414    [1719, 82, 13, 888, 2, 18, 9, 65, 304, 327, 3,...\n",
       "2893    [61, 11, 8, 223, 4, 310, 236, 310, 6, 666, 907...\n",
       "1063    [54, 13, 655, 6, 21, 81, 5, 58, 55, 32, 49, 4,...\n",
       "                              ...                        \n",
       "4586    [2, 18, 8, 425, 181, 1184, 85, 5, 379, 412, 10...\n",
       "1839    [35, 188, 65, 2, 18, 154, 9, 8, 23, 200, 10, 5...\n",
       "4885    [5, 26, 42, 163, 244, 11, 161, 3, 114, 4, 81, ...\n",
       "3830    [721, 167, 113, 11, 30, 33, 237, 3, 131, 2, 18...\n",
       "781     [21, 167, 8, 13, 71, 1024, 343, 69, 16, 167, 2...\n",
       "Name: text_to_sequence_padded, Length: 3486, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbbeac2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389     [64, 110, 82, 6, 2, 50, 6, 27, 20, 174, 307, 2...\n",
       "2817    [5, 289, 3, 729, 3, 31, 585, 11, 10, 114, 25, ...\n",
       "2574    [59, 78, 47, 608, 60, 5, 612, 3, 142, 16, 18, ...\n",
       "2491    [5, 26, 8, 48, 487, 25, 33, 2123, 19, 125, 12,...\n",
       "508     [24, 15, 76, 3, 19, 4, 682, 15, 71, 110, 2, 34...\n",
       "                              ...                        \n",
       "118     [27, 52, 89, 6, 1208, 209, 302, 15, 18, 4, 116...\n",
       "4852    [71, 26, 4, 590, 1305, 17, 381, 2, 298, 12, 12...\n",
       "2422    [5, 45, 3, 31, 21, 11, 48, 22, 25, 169, 63, 16...\n",
       "3586    [3, 289, 191, 2, 18, 8, 11, 48, 3, 237, 1371, ...\n",
       "2040    [61, 14, 8, 11, 164, 127, 7, 171, 2, 1018, 2, ...\n",
       "Name: text_to_sequence_padded, Length: 1494, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "186dc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = np.zeros((len(X_train), 100))\n",
    "\n",
    "for i in range (len(X_train)):\n",
    "    X_train_tensor[i] = X_train.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf23235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486, 100)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf28fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = np.zeros((len(X_test), 100))\n",
    "\n",
    "for i in range (len(X_test)):\n",
    "    X_test_tensor[i] = X_test.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8c89143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78fcd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.stack(y_train, axis=0)  \n",
    "y_test = np.stack(y_test, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4286e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c554e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20f16b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.4361 - accuracy: 0.8652 - val_loss: 0.4445 - val_accuracy: 0.8548\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.4298 - accuracy: 0.8652 - val_loss: 0.4391 - val_accuracy: 0.8548\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.4243 - accuracy: 0.8652 - val_loss: 0.4347 - val_accuracy: 0.8548\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.4196 - accuracy: 0.8652 - val_loss: 0.4308 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.4155 - accuracy: 0.8652 - val_loss: 0.4276 - val_accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 2s 21ms/step - loss: 0.4121 - accuracy: 0.8652 - val_loss: 0.4249 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.4092 - accuracy: 0.8652 - val_loss: 0.4226 - val_accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.4067 - accuracy: 0.8652 - val_loss: 0.4208 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.4047 - accuracy: 0.8652 - val_loss: 0.4194 - val_accuracy: 0.8548\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.4029 - accuracy: 0.8652 - val_loss: 0.4182 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tensor, y_train, epochs=10, validation_data=(X_test_tensor, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da6b3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8548\n",
      "Testing Accuracy is 85.47523617744446 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_tensor,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937ea18",
   "metadata": {},
   "source": [
    "## Tunning de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9f5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_optimize(num_filters, kernel_size):\n",
    "    model = Sequential([\n",
    "      embedding_layer,\n",
    "      Conv1D(num_filters, kernel_size, activation='relu'),\n",
    "      GlobalMaxPooling1D(),\n",
    "      Dense(10, activation='relu'),\n",
    "      Dense(1, activation='sigmoid')])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e64a10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"num_filters\":[32, 64, 128, 256],\n",
    "    \"kernel_size\":[3, 5, 7, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3cc22ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-39d8cf6483ae>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=model_to_optimize,\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=model_to_optimize,\n",
    "                        epochs=10,\n",
    "                        batch_size=10,\n",
    "                        verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d32a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gridSearch = GridSearchCV(estimator=model, param_grid=params,\n",
    "                              cv=5, verbose=1)\n",
    "search_result = gridSearch.fit(X_train_tensor, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a85401f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = gridSearch.score(X_test_tensor, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e58f9840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547523617744446"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "952fda67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_size': 3, 'num_filters': 32}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c430ffd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel_size</th>\n",
       "      <th>param_num_filters</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.027215</td>\n",
       "      <td>1.868864</td>\n",
       "      <td>0.480526</td>\n",
       "      <td>0.315906</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 32}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.410204</td>\n",
       "      <td>0.413697</td>\n",
       "      <td>0.316568</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 64}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.884871</td>\n",
       "      <td>0.815737</td>\n",
       "      <td>0.362912</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 128}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.627373</td>\n",
       "      <td>2.855343</td>\n",
       "      <td>0.421252</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 3, 'num_filters': 256}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.850416</td>\n",
       "      <td>2.763449</td>\n",
       "      <td>0.397019</td>\n",
       "      <td>0.094121</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 32}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.707111</td>\n",
       "      <td>2.420253</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.036305</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 64}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.250828</td>\n",
       "      <td>0.832170</td>\n",
       "      <td>0.445916</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 128}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.514875</td>\n",
       "      <td>0.950564</td>\n",
       "      <td>0.468897</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 5, 'num_filters': 256}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.719642</td>\n",
       "      <td>1.708706</td>\n",
       "      <td>0.403449</td>\n",
       "      <td>0.100202</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 32}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.950542</td>\n",
       "      <td>1.086251</td>\n",
       "      <td>0.412990</td>\n",
       "      <td>0.022494</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 64}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.334465</td>\n",
       "      <td>3.221471</td>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.158536</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 128}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.268731</td>\n",
       "      <td>4.661106</td>\n",
       "      <td>0.505927</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>7</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 7, 'num_filters': 256}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.866425</td>\n",
       "      <td>0.685020</td>\n",
       "      <td>0.407328</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 32}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23.462862</td>\n",
       "      <td>1.032283</td>\n",
       "      <td>0.398236</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 64}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.936619</td>\n",
       "      <td>0.738644</td>\n",
       "      <td>0.471206</td>\n",
       "      <td>0.038189</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 128}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38.818572</td>\n",
       "      <td>1.156416</td>\n",
       "      <td>0.550588</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>{'kernel_size': 9, 'num_filters': 256}</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       11.027215      1.868864         0.480526        0.315906   \n",
       "1       12.410204      0.413697         0.316568        0.022203   \n",
       "2       15.884871      0.815737         0.362912        0.031326   \n",
       "3       21.627373      2.855343         0.421252        0.044966   \n",
       "4       16.850416      2.763449         0.397019        0.094121   \n",
       "5       20.707111      2.420253         0.458015        0.036305   \n",
       "6       22.250828      0.832170         0.445916        0.034098   \n",
       "7       29.514875      0.950564         0.468897        0.008381   \n",
       "8       18.719642      1.708706         0.403449        0.100202   \n",
       "9       22.950542      1.086251         0.412990        0.022494   \n",
       "10      28.334465      3.221471         0.493053        0.158536   \n",
       "11      39.268731      4.661106         0.505927        0.029039   \n",
       "12      21.866425      0.685020         0.407328        0.044457   \n",
       "13      23.462862      1.032283         0.398236        0.024771   \n",
       "14      28.936619      0.738644         0.471206        0.038189   \n",
       "15      38.818572      1.156416         0.550588        0.031990   \n",
       "\n",
       "   param_kernel_size param_num_filters  \\\n",
       "0                  3                32   \n",
       "1                  3                64   \n",
       "2                  3               128   \n",
       "3                  3               256   \n",
       "4                  5                32   \n",
       "5                  5                64   \n",
       "6                  5               128   \n",
       "7                  5               256   \n",
       "8                  7                32   \n",
       "9                  7                64   \n",
       "10                 7               128   \n",
       "11                 7               256   \n",
       "12                 9                32   \n",
       "13                 9                64   \n",
       "14                 9               128   \n",
       "15                 9               256   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "0    {'kernel_size': 3, 'num_filters': 32}           0.872493   \n",
       "1    {'kernel_size': 3, 'num_filters': 64}           0.872493   \n",
       "2   {'kernel_size': 3, 'num_filters': 128}           0.872493   \n",
       "3   {'kernel_size': 3, 'num_filters': 256}           0.872493   \n",
       "4    {'kernel_size': 5, 'num_filters': 32}           0.872493   \n",
       "5    {'kernel_size': 5, 'num_filters': 64}           0.872493   \n",
       "6   {'kernel_size': 5, 'num_filters': 128}           0.872493   \n",
       "7   {'kernel_size': 5, 'num_filters': 256}           0.872493   \n",
       "8    {'kernel_size': 7, 'num_filters': 32}           0.872493   \n",
       "9    {'kernel_size': 7, 'num_filters': 64}           0.872493   \n",
       "10  {'kernel_size': 7, 'num_filters': 128}           0.872493   \n",
       "11  {'kernel_size': 7, 'num_filters': 256}           0.872493   \n",
       "12   {'kernel_size': 9, 'num_filters': 32}           0.872493   \n",
       "13   {'kernel_size': 9, 'num_filters': 64}           0.872493   \n",
       "14  {'kernel_size': 9, 'num_filters': 128}           0.872493   \n",
       "15  {'kernel_size': 9, 'num_filters': 256}           0.872493   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.878049           0.860832           0.853659   \n",
       "1            0.878049           0.860832           0.853659   \n",
       "2            0.878049           0.860832           0.853659   \n",
       "3            0.878049           0.860832           0.853659   \n",
       "4            0.878049           0.860832           0.853659   \n",
       "5            0.878049           0.860832           0.853659   \n",
       "6            0.878049           0.860832           0.853659   \n",
       "7            0.878049           0.860832           0.853659   \n",
       "8            0.878049           0.860832           0.853659   \n",
       "9            0.878049           0.860832           0.853659   \n",
       "10           0.878049           0.860832           0.853659   \n",
       "11           0.878049           0.860832           0.853659   \n",
       "12           0.878049           0.860832           0.853659   \n",
       "13           0.878049           0.860832           0.853659   \n",
       "14           0.878049           0.860832           0.853659   \n",
       "15           0.878049           0.860832           0.853659   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.860832         0.865173        0.008828                1  \n",
       "1            0.860832         0.865173        0.008828                1  \n",
       "2            0.860832         0.865173        0.008828                1  \n",
       "3            0.860832         0.865173        0.008828                1  \n",
       "4            0.860832         0.865173        0.008828                1  \n",
       "5            0.860832         0.865173        0.008828                1  \n",
       "6            0.860832         0.865173        0.008828                1  \n",
       "7            0.860832         0.865173        0.008828                1  \n",
       "8            0.860832         0.865173        0.008828                1  \n",
       "9            0.860832         0.865173        0.008828                1  \n",
       "10           0.860832         0.865173        0.008828                1  \n",
       "11           0.860832         0.865173        0.008828                1  \n",
       "12           0.860832         0.865173        0.008828                1  \n",
       "13           0.860832         0.865173        0.008828                1  \n",
       "14           0.860832         0.865173        0.008828                1  \n",
       "15           0.860832         0.865173        0.008828                1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e100eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c432d5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9216889209671598\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score: {}\".format(f1_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3f8cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score: {}\".format(recall_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3dd4b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8547523427041499\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score: {}\".format(precision_score(y_test,gridSearch.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20004fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          498000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 624,260\n",
      "Trainable params: 126,260\n",
      "Non-trainable params: 498,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model2.add(embedding_layer)\n",
    "\n",
    "model2.add(LSTM(100, input_shape=(100,), activation='tanh'))\n",
    "\n",
    "model2.add(Dense(200, activation='relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(100, activation = \"relu\"))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(50, activation = \"relu\"))\n",
    "\n",
    "model2.add(Dense(10, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79b164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"sparse_categorical_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "503f6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "349/349 [==============================] - 22s 58ms/step - loss: 2.0452 - accuracy: 0.8635 - val_loss: 1.8030 - val_accuracy: 0.8548\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 17s 48ms/step - loss: 1.5894 - accuracy: 0.8652 - val_loss: 1.4000 - val_accuracy: 0.8548\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 14s 41ms/step - loss: 1.2336 - accuracy: 0.8652 - val_loss: 1.0984 - val_accuracy: 0.8548\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 14s 41ms/step - loss: 0.9759 - accuracy: 0.8652 - val_loss: 0.8890 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 13s 39ms/step - loss: 0.8008 - accuracy: 0.8652 - val_loss: 0.7500 - val_accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 13s 36ms/step - loss: 0.6852 - accuracy: 0.8652 - val_loss: 0.6587 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 13s 37ms/step - loss: 0.6088 - accuracy: 0.8652 - val_loss: 0.5981 - val_accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 13s 37ms/step - loss: 0.5575 - accuracy: 0.8652 - val_loss: 0.5567 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 13s 36ms/step - loss: 0.5218 - accuracy: 0.8652 - val_loss: 0.5274 - val_accuracy: 0.8548\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 13s 37ms/step - loss: 0.4962 - accuracy: 0.8652 - val_loss: 0.5060 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "results = model2.fit(\n",
    " X_train_tensor, y_train,\n",
    " epochs= 10,\n",
    " batch_size = 10,\n",
    " validation_data = (X_test_tensor, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5ebc2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 21ms/step - loss: 0.5060 - accuracy: 0.8548\n",
      "Testing Accuracy is 85.47523617744446 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test_tensor,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2811a83",
   "metadata": {},
   "source": [
    "## Tunning de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e59ce487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_optimize_lstm(units):\n",
    "    model = Sequential([\n",
    "      embedding_layer,\n",
    "      LSTM(units, input_shape=(100,), activation='tanh'),\n",
    "      Dense(200, activation='relu'),\n",
    "      Dropout(0.3),\n",
    "      Dense(100, activation = \"relu\"),\n",
    "      Dropout(0.3),\n",
    "      Dense(50, activation = \"relu\"),\n",
    "      Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "582b0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    \"units\": [100, 200, 300],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b5a01d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ton2\\AppData\\Local\\Temp/ipykernel_19484/2677964288.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model2 = KerasClassifier(build_fn=model_to_optimize_lstm,\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model2 = KerasClassifier(build_fn=model_to_optimize_lstm,\n",
    "                        epochs=10,\n",
    "                        batch_size=10,\n",
    "                        verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4bb9fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridSearch2 = GridSearchCV(estimator=model2, param_grid=params2,\n",
    "                              cv=5, verbose=1)\n",
    "search_result = gridSearch2.fit(X_train_tensor, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "158f0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = gridSearch2.score(X_test_tensor, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d37aea08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253012299537659"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "242ae088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 100}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e9dd1514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_units</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.920205</td>\n",
       "      <td>5.259111</td>\n",
       "      <td>0.868319</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>100</td>\n",
       "      <td>{'units': 100}</td>\n",
       "      <td>0.856734</td>\n",
       "      <td>0.857963</td>\n",
       "      <td>0.843615</td>\n",
       "      <td>0.849354</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.858004</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.457892</td>\n",
       "      <td>4.642684</td>\n",
       "      <td>1.370703</td>\n",
       "      <td>0.082183</td>\n",
       "      <td>200</td>\n",
       "      <td>{'units': 200}</td>\n",
       "      <td>0.861032</td>\n",
       "      <td>0.862267</td>\n",
       "      <td>0.833572</td>\n",
       "      <td>0.849354</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.855420</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.851348</td>\n",
       "      <td>3.911870</td>\n",
       "      <td>2.059389</td>\n",
       "      <td>0.080144</td>\n",
       "      <td>300</td>\n",
       "      <td>{'units': 300}</td>\n",
       "      <td>0.838109</td>\n",
       "      <td>0.859397</td>\n",
       "      <td>0.847920</td>\n",
       "      <td>0.839311</td>\n",
       "      <td>0.893831</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_units  \\\n",
       "0      81.920205      5.259111         0.868319        0.011761         100   \n",
       "1     121.457892      4.642684         1.370703        0.082183         200   \n",
       "2     237.851348      3.911870         2.059389        0.080144         300   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'units': 100}           0.856734           0.857963           0.843615   \n",
       "1  {'units': 200}           0.861032           0.862267           0.833572   \n",
       "2  {'units': 300}           0.838109           0.859397           0.847920   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.849354           0.882353         0.858004        0.013239   \n",
       "1           0.849354           0.870875         0.855420        0.012894   \n",
       "2           0.839311           0.893831         0.855714        0.020524   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                3  \n",
       "2                2  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridSearch2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e3b192c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9032258064516129\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score: {}\".format(f1_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3a954d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.9636075949367089\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Score: {}\".format(recall_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ba696a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8499651081646895\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score: {}\".format(precision_score(y_test,gridSearch2.predict(X_test_tensor))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
